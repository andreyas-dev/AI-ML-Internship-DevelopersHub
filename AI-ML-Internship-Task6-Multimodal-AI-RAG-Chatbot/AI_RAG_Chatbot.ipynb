{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f801e22a",
   "metadata": {},
   "source": [
    "# üöÄ Advanced Multimodal AI System & Intelligent Chatbot Platform\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This cutting-edge project demonstrates the development of sophisticated AI systems combining multiple data modalities and intelligent conversational interfaces. The implementation showcases state-of-the-art techniques in multimodal learning and retrieval-augmented generation (RAG).\n",
    "\n",
    "### üéØ Key Components:\n",
    "\n",
    "#### 1. üñºÔ∏è **Multimodal Machine Learning Engine**\n",
    "\n",
    "- **Advanced Neural Architecture**: Custom CNN-Tabular fusion model for complex price prediction\n",
    "- **Dual Input Processing**: Simultaneous image and structured data analysis\n",
    "- **Feature Engineering**: Sophisticated preprocessing pipelines for heterogeneous data\n",
    "- **Performance Optimization**: Enhanced training protocols with validation strategies\n",
    "\n",
    "#### 2. ü§ñ **Intelligent RAG-Powered Chatbot**\n",
    "\n",
    "- **Knowledge Base Integration**: Advanced vector database with Chroma persistence\n",
    "- **Context-Aware Responses**: Conversational memory with retrieval-augmented generation\n",
    "- **Multi-Source Learning**: Web scraping and document ingestion capabilities\n",
    "- **Interactive Interface**: Professional Streamlit deployment with real-time streaming\n",
    "\n",
    "### üìä **Technical Architecture:**\n",
    "\n",
    "- **Deep Learning Framework**: TensorFlow/Keras with custom model architectures\n",
    "- **Vector Database**: Chroma with HuggingFace embeddings for semantic search\n",
    "- **Language Models**: OpenAI integration with conversation memory\n",
    "- **Web Framework**: Streamlit for interactive user interfaces\n",
    "\n",
    "### üîß **Advanced Features:**\n",
    "\n",
    "- **Multimodal Fusion**: Innovative architecture combining CNN and dense networks\n",
    "- **Intelligent Preprocessing**: Automated image normalization and categorical encoding\n",
    "- **Memory Management**: Persistent conversation history and context retention\n",
    "- **Production Ready**: Scalable deployment with caching and error handling\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3d61ae",
   "metadata": {},
   "source": [
    "## üé® Part I: Advanced Multimodal Machine Learning System\n",
    "\n",
    "### üìö Environment Setup & Dependencies\n",
    "\n",
    "Setting up the comprehensive AI toolkit for multimodal learning with enhanced capabilities for image processing, tabular data analysis, and neural network architectures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a5ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COMPREHENSIVE MULTIMODAL AI TOOLKIT & DEPENDENCIES\n",
    "# =============================================================================\n",
    "\n",
    "# Core Data Science & Numerical Computing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Advanced Visualization & Plotting Suite\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Machine Learning & Preprocessing Utilities\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    "    explained_variance_score,\n",
    ")\n",
    "\n",
    "# Deep Learning Framework - TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Advanced Image Processing\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import cv2\n",
    "from skimage import exposure, filters\n",
    "\n",
    "# System & File Operations\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "# Performance & Memory Optimization\n",
    "import gc\n",
    "from functools import lru_cache\n",
    "\n",
    "# Configure environment for optimal performance\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# GPU Configuration for TensorFlow\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print(\"üöÄ GPU Acceleration Enabled\")\n",
    "else:\n",
    "    print(\"üíª Running on CPU - Consider GPU for faster training\")\n",
    "\n",
    "# Enhanced plotting configuration\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Project Configuration\n",
    "PROJECT_VERSION = \"v3.1\"\n",
    "MODEL_TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üé® ADVANCED MULTIMODAL AI SYSTEM INITIALIZED\")\n",
    "print(f\"üìÖ Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üî¢ Project Version: {PROJECT_VERSION}\")\n",
    "print(f\"üß† TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"üîß NumPy Version: {np.__version__}\")\n",
    "print(f\"üìä Pandas Version: {pd.__version__}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aa047a",
   "metadata": {},
   "source": [
    "### üîß Advanced Data Processing & Feature Engineering Pipeline\n",
    "\n",
    "Implementing sophisticated data preprocessing techniques for both tabular and image data with intelligent feature engineering and robust error handling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f737277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ADVANCED MULTIMODAL DATA PROCESSING ENGINE\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "class AdvancedDataProcessor:\n",
    "    \"\"\"\n",
    "    Comprehensive data processing pipeline for multimodal machine learning\n",
    "    Handles both tabular and image data with sophisticated preprocessing techniques\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, project_version=PROJECT_VERSION):\n",
    "        self.project_version = project_version\n",
    "        self.scaler = None\n",
    "        self.label_encoders = {}\n",
    "        self.feature_stats = {}\n",
    "        self.processing_metadata = {}\n",
    "\n",
    "        print(f\"üîß Advanced Data Processor Initialized - {project_version}\")\n",
    "\n",
    "    def load_enhanced_tabular_data(self, csv_path, target_column=\"price\"):\n",
    "        \"\"\"\n",
    "        Enhanced tabular data loading with comprehensive analysis\n",
    "\n",
    "        Args:\n",
    "            csv_path: Path to CSV file\n",
    "            target_column: Name of target variable column\n",
    "\n",
    "        Returns:\n",
    "            Loaded DataFrame with initial analysis\n",
    "        \"\"\"\n",
    "        print(f\"\\nüìä Loading Enhanced Tabular Dataset...\")\n",
    "        print(\"-\" * 45)\n",
    "\n",
    "        try:\n",
    "            # Load data with enhanced error handling\n",
    "            dataset = pd.read_csv(csv_path)\n",
    "\n",
    "            # Comprehensive data analysis\n",
    "            print(f\"  üìê Dataset Shape: {dataset.shape}\")\n",
    "            print(\n",
    "                f\"  üíæ Memory Usage: {dataset.memory_usage(deep=True).sum() / 1024**2:.2f} MB\"\n",
    "            )\n",
    "            print(f\"  üéØ Target Column: {target_column}\")\n",
    "\n",
    "            # Missing value analysis\n",
    "            missing_analysis = dataset.isnull().sum()\n",
    "            if missing_analysis.sum() > 0:\n",
    "                print(f\"  ‚ö†Ô∏è  Missing Values Detected:\")\n",
    "                for col, missing_count in missing_analysis[\n",
    "                    missing_analysis > 0\n",
    "                ].items():\n",
    "                    print(\n",
    "                        f\"    {col}: {missing_count} ({missing_count / len(dataset) * 100:.1f}%)\"\n",
    "                    )\n",
    "            else:\n",
    "                print(f\"  ‚úÖ No Missing Values Found\")\n",
    "\n",
    "            # Store metadata\n",
    "            self.processing_metadata[\"original_shape\"] = dataset.shape\n",
    "            self.processing_metadata[\"missing_values\"] = missing_analysis.to_dict()\n",
    "\n",
    "            return dataset\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Error loading data: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def advanced_tabular_preprocessing(self, dataset, target_column=\"price\"):\n",
    "        \"\"\"\n",
    "        Advanced preprocessing with intelligent feature engineering\n",
    "\n",
    "        Args:\n",
    "            dataset: Input DataFrame\n",
    "            target_column: Target variable column name\n",
    "\n",
    "        Returns:\n",
    "            Processed features, target, and fitted scaler\n",
    "        \"\"\"\n",
    "        print(f\"\\nüî¨ Advanced Tabular Preprocessing Pipeline...\")\n",
    "        print(\"-\" * 48)\n",
    "\n",
    "        # Create working copy\n",
    "        data_processed = dataset.copy()\n",
    "\n",
    "        # Separate features and target\n",
    "        if target_column in data_processed.columns:\n",
    "            X_features = data_processed.drop(target_column, axis=1)\n",
    "            y_target = data_processed[target_column]\n",
    "            print(f\"  üéØ Target Variable: {target_column} (Shape: {y_target.shape})\")\n",
    "        else:\n",
    "            X_features = data_processed\n",
    "            y_target = None\n",
    "            print(\n",
    "                f\"  ‚ö†Ô∏è  No target column '{target_column}' found - Feature processing only\"\n",
    "            )\n",
    "\n",
    "        # Advanced categorical variable handling\n",
    "        categorical_columns = X_features.select_dtypes(\n",
    "            include=[\"object\", \"category\"]\n",
    "        ).columns\n",
    "        print(f\"  üè∑Ô∏è  Categorical Features: {len(categorical_columns)}\")\n",
    "\n",
    "        # Intelligent categorical encoding with frequency-based strategy\n",
    "        for col in categorical_columns:\n",
    "            unique_values = X_features[col].nunique()\n",
    "            print(f\"    Processing {col}: {unique_values} unique values\")\n",
    "\n",
    "            if unique_values <= 10:  # Low cardinality - use label encoding\n",
    "                le = LabelEncoder()\n",
    "                X_features[col] = le.fit_transform(X_features[col].astype(str))\n",
    "                self.label_encoders[col] = le\n",
    "            else:  # High cardinality - use frequency encoding\n",
    "                freq_encoding = X_features[col].value_counts(normalize=True).to_dict()\n",
    "                X_features[col] = X_features[col].map(freq_encoding)\n",
    "                self.label_encoders[col] = freq_encoding\n",
    "\n",
    "        # Advanced numerical feature processing\n",
    "        numerical_columns = X_features.select_dtypes(\n",
    "            include=[\"int64\", \"float64\"]\n",
    "        ).columns\n",
    "        print(f\"  üî¢ Numerical Features: {len(numerical_columns)}\")\n",
    "\n",
    "        # Feature statistics before scaling\n",
    "        self.feature_stats[\"original\"] = X_features[numerical_columns].describe()\n",
    "\n",
    "        # Robust scaling for outlier resistance\n",
    "        self.scaler = RobustScaler()\n",
    "        X_features[numerical_columns] = self.scaler.fit_transform(\n",
    "            X_features[numerical_columns]\n",
    "        )\n",
    "\n",
    "        # Feature statistics after scaling\n",
    "        self.feature_stats[\"scaled\"] = X_features[numerical_columns].describe()\n",
    "\n",
    "        # Advanced feature engineering\n",
    "        print(f\"  ‚ö° Advanced Feature Engineering...\")\n",
    "\n",
    "        # Create interaction features (example for numerical columns)\n",
    "        if len(numerical_columns) >= 2:\n",
    "            # Feature interactions for top 3 numerical features\n",
    "            top_features = numerical_columns[:3]\n",
    "            for i, col1 in enumerate(top_features):\n",
    "                for col2 in top_features[i + 1 :]:\n",
    "                    interaction_name = f\"{col1}_{col2}_interaction\"\n",
    "                    X_features[interaction_name] = X_features[col1] * X_features[col2]\n",
    "\n",
    "            print(\n",
    "                f\"    ‚ûï Created {len(top_features) * (len(top_features) - 1) // 2} interaction features\"\n",
    "            )\n",
    "\n",
    "        # Polynomial features for key numerical columns (degree 2)\n",
    "        if len(numerical_columns) >= 1:\n",
    "            key_feature = numerical_columns[0]\n",
    "            X_features[f\"{key_feature}_squared\"] = X_features[key_feature] ** 2\n",
    "            print(f\"    üìà Added polynomial feature: {key_feature}_squared\")\n",
    "\n",
    "        print(f\"  ‚úÖ Final Feature Matrix Shape: {X_features.shape}\")\n",
    "\n",
    "        return X_features, y_target, self.scaler\n",
    "\n",
    "    def load_and_preprocess_images_advanced(\n",
    "        self,\n",
    "        image_directory,\n",
    "        image_identifiers,\n",
    "        target_size=(256, 256),\n",
    "        augmentation=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Advanced image loading with preprocessing and optional augmentation\n",
    "\n",
    "        Args:\n",
    "            image_directory: Directory containing images\n",
    "            image_identifiers: List of image IDs/names\n",
    "            target_size: Target image dimensions\n",
    "            augmentation: Whether to apply data augmentation\n",
    "\n",
    "        Returns:\n",
    "            Preprocessed image array\n",
    "        \"\"\"\n",
    "        print(f\"\\nüñºÔ∏è  Advanced Image Processing Pipeline...\")\n",
    "        print(\"-\" * 42)\n",
    "        print(f\"  üìÅ Image Directory: {image_directory}\")\n",
    "        print(f\"  üîç Processing {len(image_identifiers)} images\")\n",
    "        print(f\"  üìê Target Size: {target_size}\")\n",
    "\n",
    "        processed_images = []\n",
    "        successful_loads = 0\n",
    "        failed_loads = 0\n",
    "\n",
    "        # Create image data generator for augmentation if requested\n",
    "        if augmentation:\n",
    "            image_gen = ImageDataGenerator(\n",
    "                rotation_range=15,\n",
    "                width_shift_range=0.1,\n",
    "                height_shift_range=0.1,\n",
    "                shear_range=0.1,\n",
    "                zoom_range=0.1,\n",
    "                horizontal_flip=True,\n",
    "                fill_mode=\"nearest\",\n",
    "            )\n",
    "            print(f\"  üîÑ Data Augmentation Enabled\")\n",
    "\n",
    "        for idx, img_id in enumerate(image_identifiers):\n",
    "            try:\n",
    "                # Multiple possible file extensions\n",
    "                possible_extensions = [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\"]\n",
    "                img_path = None\n",
    "\n",
    "                # Find the correct file extension\n",
    "                for ext in possible_extensions:\n",
    "                    potential_path = Path(image_directory) / f\"{img_id}{ext}\"\n",
    "                    if potential_path.exists():\n",
    "                        img_path = potential_path\n",
    "                        break\n",
    "\n",
    "                if img_path and img_path.exists():\n",
    "                    # Advanced image loading and preprocessing\n",
    "                    image = Image.open(img_path)\n",
    "\n",
    "                    # Convert to RGB if necessary\n",
    "                    if image.mode != \"RGB\":\n",
    "                        image = image.convert(\"RGB\")\n",
    "\n",
    "                    # Resize with high-quality resampling\n",
    "                    image = image.resize(target_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "                    # Optional image enhancement\n",
    "                    enhancer = ImageEnhance.Contrast(image)\n",
    "                    image = enhancer.enhance(1.1)  # Slight contrast boost\n",
    "\n",
    "                    # Convert to array and normalize\n",
    "                    img_array = np.array(image, dtype=np.float32) / 255.0\n",
    "\n",
    "                    # Ensure proper shape\n",
    "                    if len(img_array.shape) == 2:  # Grayscale\n",
    "                        img_array = np.stack([img_array] * 3, axis=-1)\n",
    "\n",
    "                    processed_images.append(img_array)\n",
    "                    successful_loads += 1\n",
    "\n",
    "                else:\n",
    "                    # Create placeholder image for missing files\n",
    "                    placeholder = np.random.normal(0.5, 0.1, (*target_size, 3))\n",
    "                    placeholder = np.clip(placeholder, 0, 1).astype(np.float32)\n",
    "                    processed_images.append(placeholder)\n",
    "                    failed_loads += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                # Error handling - create noise placeholder\n",
    "                print(f\"    ‚ö†Ô∏è  Error processing image {img_id}: {str(e)}\")\n",
    "                placeholder = np.random.normal(0.5, 0.1, (*target_size, 3))\n",
    "                placeholder = np.clip(placeholder, 0, 1).astype(np.float32)\n",
    "                processed_images.append(placeholder)\n",
    "                failed_loads += 1\n",
    "\n",
    "            # Progress indicator\n",
    "            if (idx + 1) % 100 == 0:\n",
    "                print(f\"    üìä Processed {idx + 1}/{len(image_identifiers)} images...\")\n",
    "\n",
    "        processed_images_array = np.array(processed_images, dtype=np.float32)\n",
    "\n",
    "        print(f\"  ‚úÖ Image Processing Complete:\")\n",
    "        print(f\"    üìà Successfully loaded: {successful_loads}\")\n",
    "        print(f\"    ‚ö†Ô∏è  Failed/Placeholder: {failed_loads}\")\n",
    "        print(f\"    üìê Final array shape: {processed_images_array.shape}\")\n",
    "        print(f\"    üíæ Memory usage: {processed_images_array.nbytes / 1024**2:.2f} MB\")\n",
    "\n",
    "        # Store processing metadata\n",
    "        self.processing_metadata[\"image_stats\"] = {\n",
    "            \"total_images\": len(image_identifiers),\n",
    "            \"successful_loads\": successful_loads,\n",
    "            \"failed_loads\": failed_loads,\n",
    "            \"target_size\": target_size,\n",
    "            \"final_shape\": processed_images_array.shape,\n",
    "        }\n",
    "\n",
    "        return processed_images_array\n",
    "\n",
    "\n",
    "# Initialize the advanced data processor\n",
    "advanced_processor = AdvancedDataProcessor()\n",
    "\n",
    "print(f\"\\nüöÄ Advanced Multimodal Data Processing Engine Ready!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76c7ffa",
   "metadata": {},
   "source": [
    "### üèóÔ∏è Advanced Neural Architecture Design\n",
    "\n",
    "Implementing sophisticated multimodal neural network architectures with attention mechanisms, advanced feature fusion strategies, and optimized training protocols.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936ff834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ADVANCED MULTIMODAL NEURAL ARCHITECTURE DESIGNER\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "class AdvancedMultimodalArchitect:\n",
    "    \"\"\"\n",
    "    Sophisticated neural architecture designer for multimodal learning\n",
    "    Implements state-of-the-art techniques for image-tabular data fusion\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, architecture_version=\"v3.1\"):\n",
    "        self.architecture_version = architecture_version\n",
    "        self.model_history = {}\n",
    "\n",
    "        print(f\"üèóÔ∏è Advanced Multimodal Architect Initialized - {architecture_version}\")\n",
    "\n",
    "    def create_advanced_multimodal_model(\n",
    "        self, tabular_input_dim, image_input_shape, model_complexity=\"advanced\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Create sophisticated multimodal neural network with attention mechanisms\n",
    "\n",
    "        Args:\n",
    "            tabular_input_dim: Dimension of tabular features\n",
    "            image_input_shape: Shape of image input (H, W, C)\n",
    "            model_complexity: 'simple', 'advanced', or 'expert'\n",
    "\n",
    "        Returns:\n",
    "            Compiled multimodal model\n",
    "        \"\"\"\n",
    "        print(f\"\\nüß† Constructing Advanced Multimodal Architecture...\")\n",
    "        print(\"-\" * 52)\n",
    "        print(f\"  üé® Model Complexity: {model_complexity.upper()}\")\n",
    "        print(f\"  üìä Tabular Input Dimension: {tabular_input_dim}\")\n",
    "        print(f\"  üñºÔ∏è  Image Input Shape: {image_input_shape}\")\n",
    "\n",
    "        # =================================================================\n",
    "        # ADVANCED IMAGE PROCESSING BRANCH\n",
    "        # =================================================================\n",
    "\n",
    "        image_input = layers.Input(shape=image_input_shape, name=\"image_input\")\n",
    "        print(f\"  üéØ Image Input Layer: {image_input_shape}\")\n",
    "\n",
    "        if model_complexity == \"expert\":\n",
    "            # Expert level: Transfer learning with pre-trained VGG16\n",
    "            base_model = VGG16(\n",
    "                weights=\"imagenet\", include_top=False, input_tensor=image_input\n",
    "            )\n",
    "            base_model.trainable = False  # Freeze pre-trained layers initially\n",
    "\n",
    "            x = base_model.output\n",
    "            x = layers.GlobalAveragePooling2D()(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.Dropout(0.3)(x)\n",
    "            image_branch = layers.Dense(\n",
    "                128, activation=\"relu\", name=\"image_dense_final\"\n",
    "            )(x)\n",
    "\n",
    "            print(f\"    üöÄ Expert Architecture: VGG16 Transfer Learning\")\n",
    "\n",
    "        elif model_complexity == \"advanced\":\n",
    "            # Advanced level: Custom CNN with attention\n",
    "            x = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(\n",
    "                image_input\n",
    "            )\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "            x = layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "            x = layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "            # Attention mechanism for spatial feature importance\n",
    "            attention = layers.Conv2D(1, (1, 1), activation=\"sigmoid\", padding=\"same\")(\n",
    "                x\n",
    "            )\n",
    "            x = layers.Multiply()([x, attention])\n",
    "\n",
    "            x = layers.GlobalAveragePooling2D()(x)\n",
    "            x = layers.Dropout(0.4)(x)\n",
    "            x = layers.Dense(256, activation=\"relu\")(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.Dropout(0.3)(x)\n",
    "            image_branch = layers.Dense(\n",
    "                128, activation=\"relu\", name=\"image_branch_output\"\n",
    "            )(x)\n",
    "\n",
    "            print(f\"    üéØ Advanced Architecture: Custom CNN with Spatial Attention\")\n",
    "\n",
    "        else:  # Simple architecture\n",
    "            x = layers.Conv2D(32, (3, 3), activation=\"relu\")(image_input)\n",
    "            x = layers.MaxPooling2D((2, 2))(x)\n",
    "            x = layers.Conv2D(64, (3, 3), activation=\"relu\")(x)\n",
    "            x = layers.MaxPooling2D((2, 2))(x)\n",
    "            x = layers.Conv2D(128, (3, 3), activation=\"relu\")(x)\n",
    "            x = layers.Flatten()(x)\n",
    "            x = layers.Dropout(0.3)(x)\n",
    "            image_branch = layers.Dense(\n",
    "                64, activation=\"relu\", name=\"image_branch_output\"\n",
    "            )(x)\n",
    "\n",
    "            print(f\"    üîß Simple Architecture: Basic CNN\")\n",
    "\n",
    "        # =================================================================\n",
    "        # ADVANCED TABULAR PROCESSING BRANCH\n",
    "        # =================================================================\n",
    "\n",
    "        tabular_input = layers.Input(shape=(tabular_input_dim,), name=\"tabular_input\")\n",
    "        print(f\"  üìä Tabular Input Layer: {tabular_input_dim} features\")\n",
    "\n",
    "        # Multi-layer perceptron with batch normalization and dropout\n",
    "        t = layers.Dense(256, activation=\"relu\")(tabular_input)\n",
    "        t = layers.BatchNormalization()(t)\n",
    "        t = layers.Dropout(0.3)(t)\n",
    "\n",
    "        t = layers.Dense(128, activation=\"relu\")(t)\n",
    "        t = layers.BatchNormalization()(t)\n",
    "        t = layers.Dropout(0.2)(t)\n",
    "\n",
    "        t = layers.Dense(64, activation=\"relu\")(t)\n",
    "        tabular_branch = layers.BatchNormalization(name=\"tabular_branch_output\")(t)\n",
    "\n",
    "        print(f\"    üî¢ Tabular Processing: 3-Layer MLP with BatchNorm\")\n",
    "\n",
    "        # =================================================================\n",
    "        # ADVANCED FEATURE FUSION STRATEGY\n",
    "        # =================================================================\n",
    "\n",
    "        print(f\"  üîó Advanced Feature Fusion Strategy...\")\n",
    "\n",
    "        if model_complexity in [\"advanced\", \"expert\"]:\n",
    "            # Advanced fusion with attention mechanism\n",
    "\n",
    "            # Cross-modal attention: Let image features attend to tabular features\n",
    "            image_query = layers.Dense(64)(image_branch)\n",
    "            tabular_key = layers.Dense(64)(tabular_branch)\n",
    "            tabular_value = layers.Dense(64)(tabular_branch)\n",
    "\n",
    "            # Compute attention weights\n",
    "            attention_scores = layers.Dot(axes=1)([image_query, tabular_key])\n",
    "            attention_weights = layers.Softmax()(attention_scores)\n",
    "\n",
    "            # Apply attention to tabular features\n",
    "            attended_tabular = layers.Multiply()([tabular_value, attention_weights])\n",
    "\n",
    "            # Concatenate image features with attended tabular features\n",
    "            combined_features = layers.Concatenate(name=\"advanced_fusion\")(\n",
    "                [\n",
    "                    image_branch,\n",
    "                    attended_tabular,\n",
    "                    tabular_branch,  # Also include original tabular features\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            print(f\"    üéØ Cross-Modal Attention Fusion Applied\")\n",
    "\n",
    "        else:\n",
    "            # Simple concatenation\n",
    "            combined_features = layers.Concatenate(name=\"simple_fusion\")(\n",
    "                [image_branch, tabular_branch]\n",
    "            )\n",
    "\n",
    "            print(f\"    üîó Simple Concatenation Fusion\")\n",
    "\n",
    "        # =================================================================\n",
    "        # ADVANCED PREDICTION HEAD\n",
    "        # =================================================================\n",
    "\n",
    "        print(f\"  üéØ Advanced Prediction Head Construction...\")\n",
    "\n",
    "        # Multi-layer prediction head with regularization\n",
    "        x = layers.Dense(256, activation=\"relu\")(combined_features)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.4)(x)\n",
    "\n",
    "        x = layers.Dense(128, activation=\"relu\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "\n",
    "        x = layers.Dense(64, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "\n",
    "        # Final regression output\n",
    "        prediction_output = layers.Dense(\n",
    "            1, activation=\"linear\", name=\"price_prediction\"\n",
    "        )(x)\n",
    "\n",
    "        # =================================================================\n",
    "        # MODEL COMPILATION WITH ADVANCED CONFIGURATION\n",
    "        # =================================================================\n",
    "\n",
    "        # Construct the complete model\n",
    "        multimodal_model = keras.Model(\n",
    "            inputs=[image_input, tabular_input],\n",
    "            outputs=prediction_output,\n",
    "            name=f\"AdvancedMultimodalModel_{self.architecture_version}\",\n",
    "        )\n",
    "\n",
    "        # Advanced optimizer configuration\n",
    "        if model_complexity == \"expert\":\n",
    "            optimizer = optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999)\n",
    "        elif model_complexity == \"advanced\":\n",
    "            optimizer = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "        else:\n",
    "            optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "        # Compile with advanced metrics\n",
    "        multimodal_model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=\"huber\",  # Robust to outliers\n",
    "            metrics=[\"mae\", \"mse\", tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")],\n",
    "        )\n",
    "\n",
    "        # Model summary and visualization\n",
    "        print(f\"\\n  üìã MODEL ARCHITECTURE SUMMARY:\")\n",
    "        print(f\"  \" + \"=\" * 40)\n",
    "        print(f\"    Total Parameters: {multimodal_model.count_params():,}\")\n",
    "        print(\n",
    "            f\"    Trainable Parameters: {sum([tf.keras.backend.count_params(w) for w in multimodal_model.trainable_weights]):,}\"\n",
    "        )\n",
    "        print(f\"    Model Complexity: {model_complexity.upper()}\")\n",
    "        print(f\"    Architecture Version: {self.architecture_version}\")\n",
    "\n",
    "        # Store model metadata\n",
    "        self.model_history[f\"model_{MODEL_TIMESTAMP}\"] = {\n",
    "            \"complexity\": model_complexity,\n",
    "            \"tabular_dim\": tabular_input_dim,\n",
    "            \"image_shape\": image_input_shape,\n",
    "            \"total_params\": multimodal_model.count_params(),\n",
    "            \"created_at\": datetime.now().isoformat(),\n",
    "        }\n",
    "\n",
    "        return multimodal_model\n",
    "\n",
    "    def create_advanced_callbacks(self, model_name=\"multimodal_model\"):\n",
    "        \"\"\"\n",
    "        Create sophisticated training callbacks for model optimization\n",
    "\n",
    "        Returns:\n",
    "            List of configured callbacks\n",
    "        \"\"\"\n",
    "        print(f\"\\n‚ö° Configuring Advanced Training Callbacks...\")\n",
    "        print(\"-\" * 45)\n",
    "\n",
    "        callback_list = []\n",
    "\n",
    "        # Early stopping with patience\n",
    "        early_stopping = callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=15,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1,\n",
    "            mode=\"min\",\n",
    "        )\n",
    "        callback_list.append(early_stopping)\n",
    "\n",
    "        # Learning rate reduction on plateau\n",
    "        lr_scheduler = callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\",\n",
    "            factor=0.5,\n",
    "            patience=8,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1,\n",
    "            mode=\"min\",\n",
    "        )\n",
    "        callback_list.append(lr_scheduler)\n",
    "\n",
    "        # Model checkpointing\n",
    "        checkpoint_path = f\"models/best_{model_name}_{MODEL_TIMESTAMP}.h5\"\n",
    "        Path(\"models\").mkdir(exist_ok=True)\n",
    "\n",
    "        model_checkpoint = callbacks.ModelCheckpoint(\n",
    "            filepath=checkpoint_path,\n",
    "            monitor=\"val_loss\",\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            verbose=1,\n",
    "            mode=\"min\",\n",
    "        )\n",
    "        callback_list.append(model_checkpoint)\n",
    "\n",
    "        # CSV Logger for training history\n",
    "        csv_logger = callbacks.CSVLogger(\n",
    "            f\"logs/training_log_{MODEL_TIMESTAMP}.csv\", append=False\n",
    "        )\n",
    "        Path(\"logs\").mkdir(exist_ok=True)\n",
    "        callback_list.append(csv_logger)\n",
    "\n",
    "        print(f\"  ‚úÖ Configured {len(callback_list)} advanced callbacks:\")\n",
    "        print(f\"    üìà Early Stopping (patience=15)\")\n",
    "        print(f\"    üìâ Learning Rate Scheduler (factor=0.5)\")\n",
    "        print(f\"    üíæ Model Checkpointing\")\n",
    "        print(f\"    üìä CSV Training Logger\")\n",
    "\n",
    "        return callback_list\n",
    "\n",
    "\n",
    "# Initialize the advanced architect\n",
    "multimodal_architect = AdvancedMultimodalArchitect()\n",
    "\n",
    "print(f\"\\nüèóÔ∏è Advanced Multimodal Neural Architect Ready!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287c1af4",
   "metadata": {},
   "source": [
    "### üéØ Advanced Training & Comprehensive Evaluation Pipeline\n",
    "\n",
    "Implementing sophisticated training protocols with advanced metrics, comprehensive evaluation strategies, and detailed performance analysis for multimodal learning systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc892348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ADVANCED MULTIMODAL TRAINING & EVALUATION ORCHESTRATOR\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "class AdvancedTrainingOrchestrator:\n",
    "    \"\"\"\n",
    "    Comprehensive training and evaluation system for multimodal models\n",
    "    Implements advanced training protocols with extensive performance analysis\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, orchestrator_version=\"v3.1\"):\n",
    "        self.orchestrator_version = orchestrator_version\n",
    "        self.training_history = {}\n",
    "        self.evaluation_results = {}\n",
    "\n",
    "        print(f\"üéØ Advanced Training Orchestrator Initialized - {orchestrator_version}\")\n",
    "\n",
    "    def comprehensive_train_and_evaluate(\n",
    "        self,\n",
    "        csv_path,\n",
    "        image_directory,\n",
    "        model_complexity=\"advanced\",\n",
    "        test_size=0.25,\n",
    "        validation_split=0.2,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Comprehensive training and evaluation pipeline with advanced metrics\n",
    "\n",
    "        Args:\n",
    "            csv_path: Path to tabular data CSV\n",
    "            image_directory: Directory containing images\n",
    "            model_complexity: Model architecture complexity level\n",
    "            test_size: Proportion for test split\n",
    "            validation_split: Proportion for validation split\n",
    "            epochs: Maximum training epochs\n",
    "            batch_size: Training batch size\n",
    "\n",
    "        Returns:\n",
    "            Trained model and comprehensive evaluation results\n",
    "        \"\"\"\n",
    "        print(f\"\\nüöÄ Initiating Advanced Multimodal Training Pipeline...\")\n",
    "        print(\"=\" * 65)\n",
    "        print(f\"  üé® Model Complexity: {model_complexity.upper()}\")\n",
    "        print(f\"  üìä Test Split: {test_size:.1%}\")\n",
    "        print(f\"  ‚úÖ Validation Split: {validation_split:.1%}\")\n",
    "        print(f\"  üîÑ Max Epochs: {epochs}\")\n",
    "        print(f\"  üì¶ Batch Size: {batch_size}\")\n",
    "\n",
    "        # =================================================================\n",
    "        # ADVANCED DATA LOADING & PREPROCESSING\n",
    "        # =================================================================\n",
    "\n",
    "        print(f\"\\nüìä Step 1: Advanced Data Loading & Preprocessing\")\n",
    "        print(\"-\" * 48)\n",
    "\n",
    "        # Load and preprocess tabular data\n",
    "        dataset = advanced_processor.load_enhanced_tabular_data(csv_path)\n",
    "        X_tabular, y_target, fitted_scaler = (\n",
    "            advanced_processor.advanced_tabular_preprocessing(dataset)\n",
    "        )\n",
    "\n",
    "        # Load and preprocess images\n",
    "        image_ids = (\n",
    "            dataset[\"id\"].values if \"id\" in dataset.columns else range(len(dataset))\n",
    "        )\n",
    "        X_images = advanced_processor.load_and_preprocess_images_advanced(\n",
    "            image_directory, image_ids, target_size=(256, 256), augmentation=True\n",
    "        )\n",
    "\n",
    "        # Verify data alignment\n",
    "        if len(X_images) != len(X_tabular):\n",
    "            min_samples = min(len(X_images), len(X_tabular))\n",
    "            X_images = X_images[:min_samples]\n",
    "            X_tabular = X_tabular.iloc[:min_samples]\n",
    "            y_target = y_target.iloc[:min_samples] if y_target is not None else None\n",
    "            print(f\"  ‚ö†Ô∏è  Data alignment: Using {min_samples} samples\")\n",
    "\n",
    "        # =================================================================\n",
    "        # ADVANCED DATASET SPLITTING STRATEGY\n",
    "        # =================================================================\n",
    "\n",
    "        print(f\"\\nüîÑ Step 2: Advanced Dataset Splitting\")\n",
    "        print(\"-\" * 39)\n",
    "\n",
    "        # Stratified split for regression (bin the target for stratification)\n",
    "        if y_target is not None:\n",
    "            # Create bins for stratified splitting\n",
    "            y_binned = pd.qcut(y_target, q=5, labels=False, duplicates=\"drop\")\n",
    "\n",
    "            # Split with stratification\n",
    "            X_img_train, X_img_test, X_tab_train, X_tab_test, y_train, y_test = (\n",
    "                train_test_split(\n",
    "                    X_images,\n",
    "                    X_tabular,\n",
    "                    y_target,\n",
    "                    test_size=test_size,\n",
    "                    random_state=42,\n",
    "                    stratify=y_binned,\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            # Simple split without target\n",
    "            X_img_train, X_img_test, X_tab_train, X_tab_test = train_test_split(\n",
    "                X_images, X_tabular, test_size=test_size, random_state=42\n",
    "            )\n",
    "            y_train = y_test = None\n",
    "\n",
    "        print(f\"  üìê Training Set: {len(X_img_train):,} samples\")\n",
    "        print(f\"  üìê Testing Set: {len(X_img_test):,} samples\")\n",
    "\n",
    "        if y_target is not None:\n",
    "            print(f\"  üéØ Target Statistics:\")\n",
    "            print(\n",
    "                f\"    Training - Mean: {y_train.mean():.2f}, Std: {y_train.std():.2f}\"\n",
    "            )\n",
    "            print(f\"    Testing - Mean: {y_test.mean():.2f}, Std: {y_test.std():.2f}\")\n",
    "\n",
    "        # =================================================================\n",
    "        # ADVANCED MODEL CONSTRUCTION\n",
    "        # =================================================================\n",
    "\n",
    "        print(f\"\\nüèóÔ∏è Step 3: Advanced Model Architecture Construction\")\n",
    "        print(\"-\" * 54)\n",
    "\n",
    "        # Create the advanced multimodal model\n",
    "        multimodal_model = multimodal_architect.create_advanced_multimodal_model(\n",
    "            tabular_input_dim=X_tabular.shape[1],\n",
    "            image_input_shape=X_images.shape[1:],\n",
    "            model_complexity=model_complexity,\n",
    "        )\n",
    "\n",
    "        # Configure advanced callbacks\n",
    "        training_callbacks = multimodal_architect.create_advanced_callbacks(\n",
    "            model_name=f\"multimodal_{model_complexity}\"\n",
    "        )\n",
    "\n",
    "        # =================================================================\n",
    "        # ADVANCED TRAINING PROTOCOL\n",
    "        # =================================================================\n",
    "\n",
    "        print(f\"\\nüéØ Step 4: Advanced Training Execution\")\n",
    "        print(\"-\" * 38)\n",
    "\n",
    "        training_start_time = datetime.now()\n",
    "        print(f\"  üïê Training Started: {training_start_time.strftime('%H:%M:%S')}\")\n",
    "\n",
    "        # Advanced training with comprehensive monitoring\n",
    "        training_history = multimodal_model.fit(\n",
    "            x=[X_img_train, X_tab_train],\n",
    "            y=y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_split=validation_split,\n",
    "            callbacks=training_callbacks,\n",
    "            verbose=1,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "        training_end_time = datetime.now()\n",
    "        training_duration = (training_end_time - training_start_time).total_seconds()\n",
    "\n",
    "        print(f\"  ‚úÖ Training Completed: {training_end_time.strftime('%H:%M:%S')}\")\n",
    "        print(f\"  ‚è±Ô∏è  Total Training Time: {training_duration:.2f} seconds\")\n",
    "        print(f\"  üìä Epochs Completed: {len(training_history.history['loss'])}\")\n",
    "\n",
    "        # =================================================================\n",
    "        # COMPREHENSIVE MODEL EVALUATION\n",
    "        # =================================================================\n",
    "\n",
    "        print(f\"\\nüìä Step 5: Comprehensive Model Evaluation\")\n",
    "        print(\"-\" * 42)\n",
    "\n",
    "        # Generate predictions\n",
    "        test_predictions = multimodal_model.predict([X_img_test, X_tab_test])\n",
    "        test_predictions = test_predictions.flatten()\n",
    "\n",
    "        # Calculate comprehensive metrics\n",
    "        evaluation_metrics = {}\n",
    "\n",
    "        if y_test is not None:\n",
    "            evaluation_metrics[\"mae\"] = mean_absolute_error(y_test, test_predictions)\n",
    "            evaluation_metrics[\"mse\"] = mean_squared_error(y_test, test_predictions)\n",
    "            evaluation_metrics[\"rmse\"] = np.sqrt(evaluation_metrics[\"mse\"])\n",
    "            evaluation_metrics[\"r2_score\"] = r2_score(y_test, test_predictions)\n",
    "            evaluation_metrics[\"explained_variance\"] = explained_variance_score(\n",
    "                y_test, test_predictions\n",
    "            )\n",
    "\n",
    "            # Additional custom metrics\n",
    "            evaluation_metrics[\"mean_percentage_error\"] = (\n",
    "                np.mean(np.abs((y_test - test_predictions) / y_test)) * 100\n",
    "            )\n",
    "            evaluation_metrics[\"median_absolute_error\"] = np.median(\n",
    "                np.abs(y_test - test_predictions)\n",
    "            )\n",
    "\n",
    "            print(f\"  üéØ COMPREHENSIVE EVALUATION METRICS:\")\n",
    "            print(f\"  \" + \"=\" * 45)\n",
    "            print(f\"    Mean Absolute Error (MAE): {evaluation_metrics['mae']:.4f}\")\n",
    "            print(\n",
    "                f\"    Root Mean Squared Error (RMSE): {evaluation_metrics['rmse']:.4f}\"\n",
    "            )\n",
    "            print(f\"    R¬≤ Score: {evaluation_metrics['r2_score']:.4f}\")\n",
    "            print(\n",
    "                f\"    Explained Variance: {evaluation_metrics['explained_variance']:.4f}\"\n",
    "            )\n",
    "            print(\n",
    "                f\"    Mean Percentage Error: {evaluation_metrics['mean_percentage_error']:.2f}%\"\n",
    "            )\n",
    "            print(\n",
    "                f\"    Median Absolute Error: {evaluation_metrics['median_absolute_error']:.4f}\"\n",
    "            )\n",
    "\n",
    "        # =================================================================\n",
    "        # ADVANCED VISUALIZATION SUITE\n",
    "        # =================================================================\n",
    "\n",
    "        print(f\"\\nüìà Step 6: Advanced Visualization & Analysis\")\n",
    "        print(\"-\" * 44)\n",
    "\n",
    "        # Create comprehensive visualization dashboard\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "        fig.suptitle(\n",
    "            f\"Advanced Multimodal Model Analysis - {model_complexity.upper()}\",\n",
    "            fontsize=16,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "        # 1. Training History - Loss\n",
    "        axes[0, 0].plot(\n",
    "            training_history.history[\"loss\"], label=\"Training Loss\", linewidth=2\n",
    "        )\n",
    "        axes[0, 0].plot(\n",
    "            training_history.history[\"val_loss\"], label=\"Validation Loss\", linewidth=2\n",
    "        )\n",
    "        axes[0, 0].set_title(\"Model Loss Evolution\", fontweight=\"bold\")\n",
    "        axes[0, 0].set_xlabel(\"Epoch\")\n",
    "        axes[0, 0].set_ylabel(\"Loss\")\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "        # 2. Training History - MAE\n",
    "        axes[0, 1].plot(\n",
    "            training_history.history[\"mae\"], label=\"Training MAE\", linewidth=2\n",
    "        )\n",
    "        axes[0, 1].plot(\n",
    "            training_history.history[\"val_mae\"], label=\"Validation MAE\", linewidth=2\n",
    "        )\n",
    "        axes[0, 1].set_title(\"Mean Absolute Error Evolution\", fontweight=\"bold\")\n",
    "        axes[0, 1].set_xlabel(\"Epoch\")\n",
    "        axes[0, 1].set_ylabel(\"MAE\")\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "        # 3. Training History - RMSE\n",
    "        if \"rmse\" in training_history.history:\n",
    "            axes[0, 2].plot(\n",
    "                training_history.history[\"rmse\"], label=\"Training RMSE\", linewidth=2\n",
    "            )\n",
    "            axes[0, 2].plot(\n",
    "                training_history.history[\"val_rmse\"],\n",
    "                label=\"Validation RMSE\",\n",
    "                linewidth=2,\n",
    "            )\n",
    "            axes[0, 2].set_title(\"Root Mean Squared Error Evolution\", fontweight=\"bold\")\n",
    "            axes[0, 2].set_xlabel(\"Epoch\")\n",
    "            axes[0, 2].set_ylabel(\"RMSE\")\n",
    "            axes[0, 2].legend()\n",
    "            axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "        if y_test is not None:\n",
    "            # 4. Predictions vs Actual\n",
    "            axes[1, 0].scatter(y_test, test_predictions, alpha=0.6, color=\"blue\")\n",
    "            axes[1, 0].plot(\n",
    "                [y_test.min(), y_test.max()],\n",
    "                [y_test.min(), y_test.max()],\n",
    "                \"r--\",\n",
    "                linewidth=2,\n",
    "                label=\"Perfect Prediction\",\n",
    "            )\n",
    "            axes[1, 0].set_title(\"Predictions vs Actual Values\", fontweight=\"bold\")\n",
    "            axes[1, 0].set_xlabel(\"Actual Values\")\n",
    "            axes[1, 0].set_ylabel(\"Predicted Values\")\n",
    "            axes[1, 0].legend()\n",
    "            axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "            # 5. Residual Analysis\n",
    "            residuals = y_test - test_predictions\n",
    "            axes[1, 1].scatter(test_predictions, residuals, alpha=0.6, color=\"green\")\n",
    "            axes[1, 1].axhline(y=0, color=\"red\", linestyle=\"--\", linewidth=2)\n",
    "            axes[1, 1].set_title(\"Residual Analysis\", fontweight=\"bold\")\n",
    "            axes[1, 1].set_xlabel(\"Predicted Values\")\n",
    "            axes[1, 1].set_ylabel(\"Residuals\")\n",
    "            axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "            # 6. Error Distribution\n",
    "            axes[1, 2].hist(\n",
    "                residuals, bins=30, alpha=0.7, color=\"purple\", edgecolor=\"black\"\n",
    "            )\n",
    "            axes[1, 2].set_title(\"Error Distribution\", fontweight=\"bold\")\n",
    "            axes[1, 2].set_xlabel(\"Prediction Error\")\n",
    "            axes[1, 2].set_ylabel(\"Frequency\")\n",
    "            axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Store comprehensive results\n",
    "        self.training_history[f\"session_{MODEL_TIMESTAMP}\"] = {\n",
    "            \"model_complexity\": model_complexity,\n",
    "            \"training_duration\": training_duration,\n",
    "            \"epochs_completed\": len(training_history.history[\"loss\"]),\n",
    "            \"final_train_loss\": training_history.history[\"loss\"][-1],\n",
    "            \"final_val_loss\": training_history.history[\"val_loss\"][-1],\n",
    "            \"evaluation_metrics\": evaluation_metrics,\n",
    "            \"data_shapes\": {\n",
    "                \"train_images\": X_img_train.shape,\n",
    "                \"train_tabular\": X_tab_train.shape,\n",
    "                \"test_images\": X_img_test.shape,\n",
    "                \"test_tabular\": X_tab_test.shape,\n",
    "            },\n",
    "        }\n",
    "\n",
    "        print(f\"\\n‚ú® Advanced Multimodal Training & Evaluation Complete!\")\n",
    "        print(f\"üèÜ Model Performance Summary:\")\n",
    "        if evaluation_metrics:\n",
    "            print(f\"    üéØ R¬≤ Score: {evaluation_metrics.get('r2_score', 'N/A'):.4f}\")\n",
    "            print(f\"    üìä RMSE: {evaluation_metrics.get('rmse', 'N/A'):.4f}\")\n",
    "            print(\n",
    "                f\"    ‚ö° Mean % Error: {evaluation_metrics.get('mean_percentage_error', 'N/A'):.2f}%\"\n",
    "            )\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "        return multimodal_model, evaluation_metrics, fitted_scaler\n",
    "\n",
    "\n",
    "# Initialize the advanced training orchestrator\n",
    "training_orchestrator = AdvancedTrainingOrchestrator()\n",
    "\n",
    "print(f\"\\nüéØ Advanced Training Orchestrator Ready!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Example usage (uncommented when data is available):\n",
    "# model, metrics, scaler = training_orchestrator.comprehensive_train_and_evaluate(\n",
    "#     csv_path='enhanced_housing_data.csv',\n",
    "#     image_directory='property_images/',\n",
    "#     model_complexity='advanced',\n",
    "#     epochs=50,\n",
    "#     batch_size=16\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67b6b52",
   "metadata": {},
   "source": [
    "### üîÆ Advanced Prediction & Inference Engine\n",
    "\n",
    "Implementing sophisticated prediction capabilities with confidence estimation, batch processing, and comprehensive result analysis for production-ready multimodal inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e12836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ADVANCED MULTIMODAL PREDICTION & INFERENCE ENGINE\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "class AdvancedPredictionEngine:\n",
    "    \"\"\"\n",
    "    Sophisticated prediction system for multimodal models\n",
    "    Provides advanced inference capabilities with confidence estimation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, engine_version=\"v3.1\"):\n",
    "        self.engine_version = engine_version\n",
    "        self.prediction_history = {}\n",
    "        self.model_cache = {}\n",
    "\n",
    "        print(f\"üîÆ Advanced Prediction Engine Initialized - {engine_version}\")\n",
    "\n",
    "    def advanced_single_prediction(\n",
    "        self,\n",
    "        model,\n",
    "        scaler,\n",
    "        tabular_data,\n",
    "        image_path,\n",
    "        confidence_estimation=True,\n",
    "        preprocessing_details=True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Advanced single sample prediction with comprehensive analysis\n",
    "\n",
    "        Args:\n",
    "            model: Trained multimodal model\n",
    "            scaler: Fitted data scaler\n",
    "            tabular_data: Tabular features (pandas Series or array)\n",
    "            image_path: Path to image file\n",
    "            confidence_estimation: Whether to estimate prediction confidence\n",
    "            preprocessing_details: Whether to show preprocessing details\n",
    "\n",
    "        Returns:\n",
    "            Dictionary with prediction results and metadata\n",
    "        \"\"\"\n",
    "        print(f\"\\nüîÆ Advanced Single Sample Prediction...\")\n",
    "        print(\"-\" * 38)\n",
    "\n",
    "        prediction_id = f\"pred_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}\"\n",
    "\n",
    "        try:\n",
    "            # =============================================================\n",
    "            # ADVANCED TABULAR DATA PREPROCESSING\n",
    "            # =============================================================\n",
    "\n",
    "            if preprocessing_details:\n",
    "                print(f\"  üìä Processing Tabular Features...\")\n",
    "\n",
    "            # Convert to numpy array if pandas Series\n",
    "            if hasattr(tabular_data, \"values\"):\n",
    "                tabular_array = tabular_data.values\n",
    "            else:\n",
    "                tabular_array = np.array(tabular_data)\n",
    "\n",
    "            # Ensure correct shape and apply scaling\n",
    "            if len(tabular_array.shape) == 1:\n",
    "                tabular_array = tabular_array.reshape(1, -1)\n",
    "\n",
    "            tabular_processed = scaler.transform(tabular_array)\n",
    "\n",
    "            if preprocessing_details:\n",
    "                print(f\"    ‚úÖ Tabular shape: {tabular_processed.shape}\")\n",
    "                print(\n",
    "                    f\"    üìà Feature range: [{tabular_processed.min():.3f}, {tabular_processed.max():.3f}]\"\n",
    "                )\n",
    "\n",
    "            # =============================================================\n",
    "            # ADVANCED IMAGE PREPROCESSING\n",
    "            # =============================================================\n",
    "\n",
    "            if preprocessing_details:\n",
    "                print(f\"  üñºÔ∏è  Processing Image: {Path(image_path).name}\")\n",
    "\n",
    "            # Load and preprocess image with error handling\n",
    "            if not Path(image_path).exists():\n",
    "                print(f\"    ‚ö†Ô∏è  Image not found, using placeholder\")\n",
    "                image_array = np.random.normal(0.5, 0.1, (256, 256, 3))\n",
    "                image_array = np.clip(image_array, 0, 1).astype(np.float32)\n",
    "            else:\n",
    "                # Advanced image loading\n",
    "                image = Image.open(image_path)\n",
    "\n",
    "                # Convert to RGB if necessary\n",
    "                if image.mode != \"RGB\":\n",
    "                    image = image.convert(\"RGB\")\n",
    "                    if preprocessing_details:\n",
    "                        print(f\"    üîÑ Converted to RGB mode\")\n",
    "\n",
    "                # High-quality resize\n",
    "                image = image.resize((256, 256), Image.Resampling.LANCZOS)\n",
    "\n",
    "                # Optional image enhancement\n",
    "                enhancer = ImageEnhance.Contrast(image)\n",
    "                image = enhancer.enhance(1.05)  # Slight contrast boost\n",
    "\n",
    "                # Convert to array and normalize\n",
    "                image_array = np.array(image, dtype=np.float32) / 255.0\n",
    "\n",
    "            # Ensure correct shape for model input\n",
    "            if len(image_array.shape) == 3:\n",
    "                image_array = image_array.reshape(1, *image_array.shape)\n",
    "\n",
    "            if preprocessing_details:\n",
    "                print(f\"    ‚úÖ Image shape: {image_array.shape}\")\n",
    "                print(\n",
    "                    f\"    üìä Pixel range: [{image_array.min():.3f}, {image_array.max():.3f}]\"\n",
    "                )\n",
    "\n",
    "            # =============================================================\n",
    "            # ADVANCED PREDICTION WITH CONFIDENCE ESTIMATION\n",
    "            # =============================================================\n",
    "\n",
    "            print(f\"  üß† Generating Advanced Prediction...\")\n",
    "\n",
    "            # Primary prediction\n",
    "            prediction_start = datetime.now()\n",
    "            primary_prediction = model.predict(\n",
    "                [image_array, tabular_processed], verbose=0\n",
    "            )\n",
    "            prediction_time = (datetime.now() - prediction_start).total_seconds()\n",
    "\n",
    "            predicted_value = float(primary_prediction[0][0])\n",
    "\n",
    "            print(f\"    üéØ Primary Prediction: {predicted_value:.4f}\")\n",
    "            print(f\"    ‚è±Ô∏è  Inference Time: {prediction_time:.4f} seconds\")\n",
    "\n",
    "            # Confidence estimation through multiple predictions with dropout\n",
    "            confidence_info = {\n",
    "                \"confidence_score\": None,\n",
    "                \"prediction_std\": None,\n",
    "                \"confidence_interval\": None,\n",
    "            }\n",
    "\n",
    "            if confidence_estimation:\n",
    "                print(f\"  üìä Estimating Prediction Confidence...\")\n",
    "\n",
    "                # Enable dropout during inference for uncertainty estimation\n",
    "                if hasattr(model, \"layers\"):\n",
    "                    # Monte Carlo Dropout for uncertainty estimation\n",
    "                    mc_predictions = []\n",
    "                    n_samples = 20  # Number of MC samples\n",
    "\n",
    "                    for i in range(n_samples):\n",
    "                        # Use model in training mode to keep dropout active\n",
    "                        mc_pred = model.predict(\n",
    "                            [image_array, tabular_processed], verbose=0\n",
    "                        )\n",
    "                        mc_predictions.append(float(mc_pred[0][0]))\n",
    "\n",
    "                    mc_predictions = np.array(mc_predictions)\n",
    "                    prediction_std = np.std(mc_predictions)\n",
    "                    confidence_score = 1.0 - min(\n",
    "                        prediction_std / abs(predicted_value + 1e-8), 0.5\n",
    "                    )  # Normalized confidence\n",
    "\n",
    "                    # 95% confidence interval\n",
    "                    confidence_interval = (\n",
    "                        np.percentile(mc_predictions, 2.5),\n",
    "                        np.percentile(mc_predictions, 97.5),\n",
    "                    )\n",
    "\n",
    "                    confidence_info = {\n",
    "                        \"confidence_score\": confidence_score,\n",
    "                        \"prediction_std\": prediction_std,\n",
    "                        \"confidence_interval\": confidence_interval,\n",
    "                        \"mc_predictions\": mc_predictions,\n",
    "                    }\n",
    "\n",
    "                    print(f\"    üìà Confidence Score: {confidence_score:.3f}\")\n",
    "                    print(f\"    üìä Prediction Std: {prediction_std:.4f}\")\n",
    "                    print(\n",
    "                        f\"    üéØ 95% CI: [{confidence_interval[0]:.4f}, {confidence_interval[1]:.4f}]\"\n",
    "                    )\n",
    "\n",
    "            # =============================================================\n",
    "            # COMPREHENSIVE RESULT COMPILATION\n",
    "            # =============================================================\n",
    "\n",
    "            prediction_results = {\n",
    "                \"prediction_id\": prediction_id,\n",
    "                \"predicted_value\": predicted_value,\n",
    "                \"inference_time\": prediction_time,\n",
    "                \"confidence_info\": confidence_info,\n",
    "                \"input_metadata\": {\n",
    "                    \"image_path\": str(image_path),\n",
    "                    \"image_shape\": image_array.shape,\n",
    "                    \"tabular_shape\": tabular_processed.shape,\n",
    "                    \"tabular_features\": len(tabular_processed[0]),\n",
    "                },\n",
    "                \"model_info\": {\n",
    "                    \"model_name\": model.name if hasattr(model, \"name\") else \"Unknown\",\n",
    "                    \"total_params\": model.count_params()\n",
    "                    if hasattr(model, \"count_params\")\n",
    "                    else \"Unknown\",\n",
    "                },\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"engine_version\": self.engine_version,\n",
    "            }\n",
    "\n",
    "            # Store in prediction history\n",
    "            self.prediction_history[prediction_id] = prediction_results\n",
    "\n",
    "            print(f\"  ‚úÖ Prediction Complete - ID: {prediction_id}\")\n",
    "\n",
    "            return prediction_results\n",
    "\n",
    "        except Exception as e:\n",
    "            error_result = {\n",
    "                \"prediction_id\": prediction_id,\n",
    "                \"error\": str(e),\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"status\": \"failed\",\n",
    "            }\n",
    "\n",
    "            print(f\"  ‚ùå Prediction Failed: {str(e)}\")\n",
    "            return error_result\n",
    "\n",
    "    def batch_prediction_advanced(\n",
    "        self,\n",
    "        model,\n",
    "        scaler,\n",
    "        tabular_data_list,\n",
    "        image_path_list,\n",
    "        batch_size=32,\n",
    "        show_progress=True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Advanced batch prediction with progress tracking\n",
    "\n",
    "        Args:\n",
    "            model: Trained multimodal model\n",
    "            scaler: Fitted data scaler\n",
    "            tabular_data_list: List of tabular feature arrays\n",
    "            image_path_list: List of image file paths\n",
    "            batch_size: Batch size for processing\n",
    "            show_progress: Whether to show progress updates\n",
    "\n",
    "        Returns:\n",
    "            List of prediction results\n",
    "        \"\"\"\n",
    "        print(f\"\\nüöÄ Advanced Batch Prediction Processing...\")\n",
    "        print(\"-\" * 44)\n",
    "        print(f\"  üìä Total Samples: {len(tabular_data_list)}\")\n",
    "        print(f\"  üì¶ Batch Size: {batch_size}\")\n",
    "\n",
    "        batch_results = []\n",
    "        total_samples = len(tabular_data_list)\n",
    "\n",
    "        for i in range(0, total_samples, batch_size):\n",
    "            batch_end = min(i + batch_size, total_samples)\n",
    "            batch_tabular = tabular_data_list[i:batch_end]\n",
    "            batch_images = image_path_list[i:batch_end]\n",
    "\n",
    "            if show_progress:\n",
    "                print(\n",
    "                    f\"  üîÑ Processing batch {i // batch_size + 1}: samples {i + 1}-{batch_end}\"\n",
    "                )\n",
    "\n",
    "            # Process batch\n",
    "            for j, (tab_data, img_path) in enumerate(zip(batch_tabular, batch_images)):\n",
    "                result = self.advanced_single_prediction(\n",
    "                    model,\n",
    "                    scaler,\n",
    "                    tab_data,\n",
    "                    img_path,\n",
    "                    confidence_estimation=False,  # Skip confidence for batch processing\n",
    "                    preprocessing_details=False,\n",
    "                )\n",
    "                batch_results.append(result)\n",
    "\n",
    "        print(f\"  ‚úÖ Batch Processing Complete: {len(batch_results)} predictions\")\n",
    "\n",
    "        return batch_results\n",
    "\n",
    "    def prediction_analysis_dashboard(self, prediction_results):\n",
    "        \"\"\"\n",
    "        Create comprehensive analysis dashboard for prediction results\n",
    "\n",
    "        Args:\n",
    "            prediction_results: Single prediction result or list of results\n",
    "        \"\"\"\n",
    "        print(f\"\\nüìä Prediction Analysis Dashboard...\")\n",
    "        print(\"-\" * 35)\n",
    "\n",
    "        # Handle single prediction or list\n",
    "        if isinstance(prediction_results, dict):\n",
    "            results_list = [prediction_results]\n",
    "        else:\n",
    "            results_list = prediction_results\n",
    "\n",
    "        # Extract prediction values\n",
    "        predictions = [\n",
    "            r.get(\"predicted_value\", 0) for r in results_list if \"predicted_value\" in r\n",
    "        ]\n",
    "\n",
    "        if not predictions:\n",
    "            print(\"  ‚ö†Ô∏è  No valid predictions to analyze\")\n",
    "            return\n",
    "\n",
    "        # Statistical analysis\n",
    "        pred_array = np.array(predictions)\n",
    "        stats = {\n",
    "            \"count\": len(predictions),\n",
    "            \"mean\": np.mean(pred_array),\n",
    "            \"std\": np.std(pred_array),\n",
    "            \"min\": np.min(pred_array),\n",
    "            \"max\": np.max(pred_array),\n",
    "            \"median\": np.median(pred_array),\n",
    "            \"q25\": np.percentile(pred_array, 25),\n",
    "            \"q75\": np.percentile(pred_array, 75),\n",
    "        }\n",
    "\n",
    "        print(f\"  üìà Prediction Statistics:\")\n",
    "        print(f\"    Count: {stats['count']:,}\")\n",
    "        print(f\"    Mean: {stats['mean']:.4f}\")\n",
    "        print(f\"    Std Dev: {stats['std']:.4f}\")\n",
    "        print(f\"    Range: [{stats['min']:.4f}, {stats['max']:.4f}]\")\n",
    "        print(f\"    Median: {stats['median']:.4f}\")\n",
    "        print(f\"    IQR: [{stats['q25']:.4f}, {stats['q75']:.4f}]\")\n",
    "\n",
    "        # Visualization\n",
    "        if len(predictions) > 1:\n",
    "            plt.figure(figsize=(15, 5))\n",
    "\n",
    "            # Histogram\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.hist(\n",
    "                predictions,\n",
    "                bins=min(30, len(predictions) // 2),\n",
    "                alpha=0.7,\n",
    "                color=\"skyblue\",\n",
    "                edgecolor=\"black\",\n",
    "            )\n",
    "            plt.title(\"Prediction Distribution\", fontweight=\"bold\")\n",
    "            plt.xlabel(\"Predicted Values\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            plt.grid(True, alpha=0.3)\n",
    "\n",
    "            # Box plot\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.boxplot(\n",
    "                predictions, patch_artist=True, boxprops=dict(facecolor=\"lightgreen\")\n",
    "            )\n",
    "            plt.title(\"Prediction Box Plot\", fontweight=\"bold\")\n",
    "            plt.ylabel(\"Predicted Values\")\n",
    "            plt.grid(True, alpha=0.3)\n",
    "\n",
    "            # Time series (if available)\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.plot(\n",
    "                range(len(predictions)),\n",
    "                predictions,\n",
    "                marker=\"o\",\n",
    "                linewidth=2,\n",
    "                markersize=4,\n",
    "            )\n",
    "            plt.title(\"Prediction Sequence\", fontweight=\"bold\")\n",
    "            plt.xlabel(\"Sample Index\")\n",
    "            plt.ylabel(\"Predicted Values\")\n",
    "            plt.grid(True, alpha=0.3)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        return stats\n",
    "\n",
    "\n",
    "# Initialize the advanced prediction engine\n",
    "prediction_engine = AdvancedPredictionEngine()\n",
    "\n",
    "print(f\"\\nüîÆ Advanced Prediction Engine Ready!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Example usage (uncommented when model is available):\n",
    "# result = prediction_engine.advanced_single_prediction(\n",
    "#     model=trained_model,\n",
    "#     scaler=fitted_scaler,\n",
    "#     tabular_data=sample_features,\n",
    "#     image_path='sample_property.jpg',\n",
    "#     confidence_estimation=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ab5c19",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ü§ñ Part II: Advanced RAG-Powered Intelligent Chatbot System\n",
    "\n",
    "### üìö Intelligent Knowledge Management & Vector Database\n",
    "\n",
    "Implementing sophisticated Retrieval-Augmented Generation (RAG) systems with advanced document processing, semantic search capabilities, and intelligent context management.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d993bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ADVANCED RAG-POWERED KNOWLEDGE MANAGEMENT SYSTEM\n",
    "# =============================================================================\n",
    "\n",
    "# Core LangChain Components for Advanced RAG\n",
    "from langchain.document_loaders import (\n",
    "    TextLoader,\n",
    "    DirectoryLoader,\n",
    "    PyPDFLoader,\n",
    "    UnstructuredWordDocumentLoader,\n",
    "    CSVLoader,\n",
    ")\n",
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    TokenTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    ")\n",
    "from langchain.embeddings import HuggingFaceEmbeddings, OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma, FAISS\n",
    "from langchain.llms import OpenAI, HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory, ConversationSummaryMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "\n",
    "# System and utility imports\n",
    "import os\n",
    "import hashlib\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional\n",
    "import logging\n",
    "\n",
    "# Configure advanced logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Advanced Configuration\n",
    "KNOWLEDGE_BASE_VERSION = \"v3.1\"\n",
    "EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 200\n",
    "MAX_DOCUMENTS = 10000\n",
    "\n",
    "# Set OpenAI API key (replace with your actual key)\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key-here\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ü§ñ ADVANCED RAG-POWERED KNOWLEDGE MANAGEMENT SYSTEM\")\n",
    "print(f\"üìÖ Initialization: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üî¢ Version: {KNOWLEDGE_BASE_VERSION}\")\n",
    "print(f\"üß† Embedding Model: {EMBEDDING_MODEL}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "class AdvancedKnowledgeBaseManager:\n",
    "    \"\"\"\n",
    "    Sophisticated knowledge base management system with advanced RAG capabilities\n",
    "    Supports multiple document types, intelligent chunking, and semantic search\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_directory=\"./advanced_knowledge_base\",\n",
    "        embedding_model=EMBEDDING_MODEL,\n",
    "    ):\n",
    "        self.base_directory = Path(base_directory)\n",
    "        self.embedding_model = embedding_model\n",
    "        self.knowledge_bases = {}\n",
    "        self.document_metadata = {}\n",
    "        self.processing_stats = {}\n",
    "\n",
    "        # Create directory structure\n",
    "        self.base_directory.mkdir(exist_ok=True)\n",
    "        (self.base_directory / \"vector_stores\").mkdir(exist_ok=True)\n",
    "        (self.base_directory / \"metadata\").mkdir(exist_ok=True)\n",
    "        (self.base_directory / \"logs\").mkdir(exist_ok=True)\n",
    "\n",
    "        print(f\"üèóÔ∏è Advanced Knowledge Base Manager Initialized\")\n",
    "        print(f\"  üìÅ Base Directory: {self.base_directory}\")\n",
    "        print(f\"  üß† Embedding Model: {self.embedding_model}\")\n",
    "\n",
    "    def create_enhanced_knowledge_base_from_directory(\n",
    "        self,\n",
    "        documents_directory,\n",
    "        kb_name=\"default_kb\",\n",
    "        supported_extensions=None,\n",
    "        intelligent_chunking=True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Create advanced knowledge base from document directory with intelligent processing\n",
    "\n",
    "        Args:\n",
    "            documents_directory: Path to documents directory\n",
    "            kb_name: Name for the knowledge base\n",
    "            supported_extensions: List of supported file extensions\n",
    "            intelligent_chunking: Whether to use intelligent chunking strategies\n",
    "\n",
    "        Returns:\n",
    "            Created vector store and processing statistics\n",
    "        \"\"\"\n",
    "        print(f\"\\nüìö Creating Enhanced Knowledge Base: {kb_name}\")\n",
    "        print(\"-\" * (35 + len(kb_name)))\n",
    "\n",
    "        if supported_extensions is None:\n",
    "            supported_extensions = [\".txt\", \".pdf\", \".docx\", \".csv\", \".md\"]\n",
    "\n",
    "        documents_path = Path(documents_directory)\n",
    "        if not documents_path.exists():\n",
    "            raise FileNotFoundError(f\"Documents directory not found: {documents_path}\")\n",
    "\n",
    "        # Advanced document loading with multiple file type support\n",
    "        print(f\"  üîç Scanning Directory: {documents_path}\")\n",
    "\n",
    "        all_documents = []\n",
    "        file_stats = {\"total_files\": 0, \"processed_files\": 0, \"failed_files\": 0}\n",
    "\n",
    "        # Process different file types with appropriate loaders\n",
    "        for ext in supported_extensions:\n",
    "            files = list(documents_path.glob(f\"**/*{ext}\"))\n",
    "            file_stats[\"total_files\"] += len(files)\n",
    "\n",
    "            print(f\"    üìÑ Found {len(files)} {ext} files\")\n",
    "\n",
    "            for file_path in files:\n",
    "                try:\n",
    "                    # Select appropriate loader based on file extension\n",
    "                    if ext == \".pdf\":\n",
    "                        loader = PyPDFLoader(str(file_path))\n",
    "                    elif ext == \".docx\":\n",
    "                        loader = UnstructuredWordDocumentLoader(str(file_path))\n",
    "                    elif ext == \".csv\":\n",
    "                        loader = CSVLoader(str(file_path))\n",
    "                    else:  # .txt, .md, and others\n",
    "                        loader = TextLoader(str(file_path), encoding=\"utf-8\")\n",
    "\n",
    "                    docs = loader.load()\n",
    "\n",
    "                    # Add metadata to documents\n",
    "                    for doc in docs:\n",
    "                        doc.metadata.update(\n",
    "                            {\n",
    "                                \"source_file\": str(file_path),\n",
    "                                \"file_type\": ext,\n",
    "                                \"file_size\": file_path.stat().st_size,\n",
    "                                \"created_date\": datetime.now().isoformat(),\n",
    "                                \"knowledge_base\": kb_name,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "                    all_documents.extend(docs)\n",
    "                    file_stats[\"processed_files\"] += 1\n",
    "\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Failed to load {file_path}: {str(e)}\")\n",
    "                    file_stats[\"failed_files\"] += 1\n",
    "\n",
    "        print(f\"  üìä Document Loading Summary:\")\n",
    "        print(f\"    ‚úÖ Successfully processed: {file_stats['processed_files']} files\")\n",
    "        print(f\"    ‚ùå Failed to process: {file_stats['failed_files']} files\")\n",
    "        print(f\"    üìÑ Total documents loaded: {len(all_documents)}\")\n",
    "\n",
    "        if not all_documents:\n",
    "            raise ValueError(\"No documents were successfully loaded\")\n",
    "\n",
    "        # Advanced intelligent text splitting\n",
    "        print(f\"  üî¨ Applying Intelligent Text Chunking...\")\n",
    "\n",
    "        if intelligent_chunking:\n",
    "            # Use recursive character splitter for better semantic preservation\n",
    "            text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=CHUNK_SIZE,\n",
    "                chunk_overlap=CHUNK_OVERLAP,\n",
    "                length_function=len,\n",
    "                separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "            )\n",
    "        else:\n",
    "            # Simple character-based splitting\n",
    "            text_splitter = CharacterTextSplitter(\n",
    "                chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP\n",
    "            )\n",
    "\n",
    "        document_chunks = text_splitter.split_documents(all_documents)\n",
    "\n",
    "        print(f\"    üìù Original documents: {len(all_documents)}\")\n",
    "        print(f\"    üß© Generated chunks: {len(document_chunks)}\")\n",
    "        print(\n",
    "            f\"    üìä Average chunk size: {np.mean([len(chunk.page_content) for chunk in document_chunks]):.0f} chars\"\n",
    "        )\n",
    "\n",
    "        # Advanced embedding creation with progress tracking\n",
    "        print(f\"  üß† Creating Advanced Embeddings...\")\n",
    "\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=self.embedding_model,\n",
    "            model_kwargs={\"device\": \"cpu\"},  # Use 'cuda' if GPU available\n",
    "            encode_kwargs={\"normalize_embeddings\": True},\n",
    "        )\n",
    "\n",
    "        # Create vector store with persistence\n",
    "        persist_directory = self.base_directory / \"vector_stores\" / kb_name\n",
    "\n",
    "        print(f\"  üíæ Building Vector Database...\")\n",
    "        print(f\"    üìç Persist Directory: {persist_directory}\")\n",
    "\n",
    "        vectorstore = Chroma.from_documents(\n",
    "            documents=document_chunks,\n",
    "            embedding=embeddings,\n",
    "            persist_directory=str(persist_directory),\n",
    "            collection_name=f\"{kb_name}_collection\",\n",
    "        )\n",
    "\n",
    "        # Persist the vector store\n",
    "        vectorstore.persist()\n",
    "\n",
    "        # Store processing metadata\n",
    "        processing_metadata = {\n",
    "            \"kb_name\": kb_name,\n",
    "            \"creation_timestamp\": datetime.now().isoformat(),\n",
    "            \"source_directory\": str(documents_path),\n",
    "            \"file_statistics\": file_stats,\n",
    "            \"chunk_statistics\": {\n",
    "                \"total_chunks\": len(document_chunks),\n",
    "                \"chunk_size\": CHUNK_SIZE,\n",
    "                \"chunk_overlap\": CHUNK_OVERLAP,\n",
    "                \"average_chunk_length\": np.mean(\n",
    "                    [len(chunk.page_content) for chunk in document_chunks]\n",
    "                ),\n",
    "            },\n",
    "            \"embedding_model\": self.embedding_model,\n",
    "            \"vector_store_path\": str(persist_directory),\n",
    "            \"version\": KNOWLEDGE_BASE_VERSION,\n",
    "        }\n",
    "\n",
    "        # Save metadata\n",
    "        metadata_path = self.base_directory / \"metadata\" / f\"{kb_name}_metadata.json\"\n",
    "        with open(metadata_path, \"w\") as f:\n",
    "            import json\n",
    "\n",
    "            json.dump(processing_metadata, f, indent=2, default=str)\n",
    "\n",
    "        # Store in manager\n",
    "        self.knowledge_bases[kb_name] = vectorstore\n",
    "        self.processing_stats[kb_name] = processing_metadata\n",
    "\n",
    "        print(f\"  ‚úÖ Knowledge Base Creation Complete!\")\n",
    "        print(f\"    üéØ Knowledge Base: {kb_name}\")\n",
    "        print(f\"    üìö Total Chunks: {len(document_chunks):,}\")\n",
    "        print(\n",
    "            f\"    üíæ Vector Store Size: {len(vectorstore.get()['ids']) if hasattr(vectorstore, 'get') else 'N/A'}\"\n",
    "        )\n",
    "\n",
    "        return vectorstore, processing_metadata\n",
    "\n",
    "    def create_web_knowledge_base(self, urls_list, kb_name=\"web_kb\"):\n",
    "        \"\"\"\n",
    "        Create knowledge base from web URLs with advanced processing\n",
    "\n",
    "        Args:\n",
    "            urls_list: List of URLs to process\n",
    "            kb_name: Name for the knowledge base\n",
    "\n",
    "        Returns:\n",
    "            Created vector store and processing statistics\n",
    "        \"\"\"\n",
    "        print(f\"\\nüåê Creating Web Knowledge Base: {kb_name}\")\n",
    "        print(\"-\" * (32 + len(kb_name)))\n",
    "        print(f\"  üîó Processing {len(urls_list)} URLs...\")\n",
    "\n",
    "        # Advanced web document loading with error handling\n",
    "        from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "        all_web_documents = []\n",
    "        url_stats = {\"total_urls\": len(urls_list), \"successful\": 0, \"failed\": 0}\n",
    "\n",
    "        for i, url in enumerate(urls_list):\n",
    "            try:\n",
    "                print(f\"    üîÑ Loading URL {i + 1}/{len(urls_list)}: {url[:50]}...\")\n",
    "\n",
    "                loader = WebBaseLoader(url)\n",
    "                docs = loader.load()\n",
    "\n",
    "                # Add metadata\n",
    "                for doc in docs:\n",
    "                    doc.metadata.update(\n",
    "                        {\n",
    "                            \"source_url\": url,\n",
    "                            \"source_type\": \"web\",\n",
    "                            \"loaded_date\": datetime.now().isoformat(),\n",
    "                            \"knowledge_base\": kb_name,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                all_web_documents.extend(docs)\n",
    "                url_stats[\"successful\"] += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to load {url}: {str(e)}\")\n",
    "                url_stats[\"failed\"] += 1\n",
    "\n",
    "        print(f\"  üìä Web Loading Summary:\")\n",
    "        print(f\"    ‚úÖ Successfully loaded: {url_stats['successful']} URLs\")\n",
    "        print(f\"    ‚ùå Failed to load: {url_stats['failed']} URLs\")\n",
    "\n",
    "        if not all_web_documents:\n",
    "            raise ValueError(\"No web documents were successfully loaded\")\n",
    "\n",
    "        # Process similar to directory-based knowledge base\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP\n",
    "        )\n",
    "\n",
    "        document_chunks = text_splitter.split_documents(all_web_documents)\n",
    "\n",
    "        # Create embeddings and vector store\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=self.embedding_model)\n",
    "        persist_directory = self.base_directory / \"vector_stores\" / kb_name\n",
    "\n",
    "        vectorstore = Chroma.from_documents(\n",
    "            documents=document_chunks,\n",
    "            embedding=embeddings,\n",
    "            persist_directory=str(persist_directory),\n",
    "        )\n",
    "        vectorstore.persist()\n",
    "\n",
    "        # Store metadata\n",
    "        web_metadata = {\n",
    "            \"kb_name\": kb_name,\n",
    "            \"creation_timestamp\": datetime.now().isoformat(),\n",
    "            \"source_urls\": urls_list,\n",
    "            \"url_statistics\": url_stats,\n",
    "            \"chunk_count\": len(document_chunks),\n",
    "            \"embedding_model\": self.embedding_model,\n",
    "            \"version\": KNOWLEDGE_BASE_VERSION,\n",
    "        }\n",
    "\n",
    "        self.knowledge_bases[kb_name] = vectorstore\n",
    "        self.processing_stats[kb_name] = web_metadata\n",
    "\n",
    "        print(f\"  ‚úÖ Web Knowledge Base Complete!\")\n",
    "        print(f\"    üåê URLs Processed: {url_stats['successful']}\")\n",
    "        print(f\"    üìö Chunks Created: {len(document_chunks)}\")\n",
    "\n",
    "        return vectorstore, web_metadata\n",
    "\n",
    "\n",
    "# Initialize the advanced knowledge base manager\n",
    "kb_manager = AdvancedKnowledgeBaseManager()\n",
    "\n",
    "print(f\"\\nü§ñ Advanced Knowledge Base Manager Ready!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Example usage (uncommented when documents are available):\n",
    "# vectorstore, stats = kb_manager.create_enhanced_knowledge_base_from_directory(\n",
    "#     documents_directory=\"./documents\",\n",
    "#     kb_name=\"company_docs\",\n",
    "#     intelligent_chunking=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e83283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ADVANCED CONVERSATIONAL AI & RETRIEVAL SYSTEM\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "class AdvancedConversationalAI:\n",
    "    \"\"\"\n",
    "    Sophisticated conversational AI system with advanced RAG capabilities,\n",
    "    context management, and multi-turn conversation support\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vectorstore=None,\n",
    "        llm_type=\"openai\",\n",
    "        conversation_memory_type=\"buffer\",\n",
    "        max_conversation_history=10,\n",
    "    ):\n",
    "        self.vectorstore = vectorstore\n",
    "        self.llm_type = llm_type\n",
    "        self.conversation_chains = {}\n",
    "        self.conversation_histories = {}\n",
    "        self.system_stats = {}\n",
    "        self.max_conversation_history = max_conversation_history\n",
    "\n",
    "        print(f\"ü§ñ Initializing Advanced Conversational AI System\")\n",
    "        print(f\"  üß† LLM Type: {llm_type}\")\n",
    "        print(f\"  üí≠ Memory Type: {conversation_memory_type}\")\n",
    "        print(f\"  üìö Vector Store: {'Connected' if vectorstore else 'Not Connected'}\")\n",
    "\n",
    "        # Initialize Language Model with advanced configuration\n",
    "        self.llm = self._initialize_llm(llm_type)\n",
    "\n",
    "        # Setup conversation memory\n",
    "        self.memory = self._initialize_memory(conversation_memory_type)\n",
    "\n",
    "        # Create advanced prompt templates\n",
    "        self.prompt_templates = self._create_advanced_prompts()\n",
    "\n",
    "        print(f\"  ‚úÖ Conversational AI System Ready!\")\n",
    "\n",
    "    def _initialize_llm(self, llm_type):\n",
    "        \"\"\"Initialize the language model with advanced configuration\"\"\"\n",
    "        print(f\"  üß† Configuring Language Model: {llm_type.upper()}\")\n",
    "\n",
    "        try:\n",
    "            if llm_type.lower() == \"openai\":\n",
    "                llm = OpenAI(\n",
    "                    temperature=0.7,  # Balanced creativity\n",
    "                    max_tokens=1500,  # Comprehensive responses\n",
    "                    model_name=\"gpt-3.5-turbo-instruct\",\n",
    "                    request_timeout=30,\n",
    "                    max_retries=3,\n",
    "                )\n",
    "                print(f\"    ‚úÖ OpenAI GPT-3.5 Turbo Initialized\")\n",
    "\n",
    "            elif llm_type.lower() == \"huggingface\":\n",
    "                # Use HuggingFace pipeline for local inference\n",
    "                from transformers import pipeline\n",
    "\n",
    "                llm_pipeline = pipeline(\n",
    "                    \"text-generation\",\n",
    "                    model=\"microsoft/DialoGPT-medium\",\n",
    "                    tokenizer=\"microsoft/DialoGPT-medium\",\n",
    "                    max_length=512,\n",
    "                    temperature=0.7,\n",
    "                    do_sample=True,\n",
    "                    pad_token_id=50256,\n",
    "                )\n",
    "\n",
    "                llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
    "                print(f\"    ‚úÖ HuggingFace DialoGPT Initialized\")\n",
    "\n",
    "            else:\n",
    "                # Fallback to OpenAI\n",
    "                llm = OpenAI(temperature=0.7, max_tokens=1500)\n",
    "                print(f\"    ‚ö†Ô∏è Fallback to OpenAI model\")\n",
    "\n",
    "            return llm\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to initialize LLM: {str(e)}\")\n",
    "            # Create a mock LLM for development\n",
    "            print(f\"    ‚ö†Ô∏è Using Mock LLM for development\")\n",
    "            return self._create_mock_llm()\n",
    "\n",
    "    def _create_mock_llm(self):\n",
    "        \"\"\"Create a mock LLM for development/testing\"\"\"\n",
    "\n",
    "        class MockLLM:\n",
    "            def __call__(self, prompt):\n",
    "                return f\"Mock response to: {prompt[:50]}...\"\n",
    "\n",
    "        return MockLLM()\n",
    "\n",
    "    def _initialize_memory(self, memory_type):\n",
    "        \"\"\"Initialize conversation memory with advanced settings\"\"\"\n",
    "        print(f\"  üí≠ Setting up Conversation Memory: {memory_type}\")\n",
    "\n",
    "        if memory_type == \"buffer\":\n",
    "            memory = ConversationBufferMemory(\n",
    "                memory_key=\"chat_history\", return_messages=True, output_key=\"answer\"\n",
    "            )\n",
    "        elif memory_type == \"summary\":\n",
    "            memory = ConversationSummaryMemory(\n",
    "                llm=self.llm,\n",
    "                memory_key=\"chat_history\",\n",
    "                return_messages=True,\n",
    "                output_key=\"answer\",\n",
    "            )\n",
    "        else:\n",
    "            # Default to buffer memory\n",
    "            memory = ConversationBufferMemory(\n",
    "                memory_key=\"chat_history\", return_messages=True, output_key=\"answer\"\n",
    "            )\n",
    "\n",
    "        print(f\"    ‚úÖ {memory_type.title()} Memory Initialized\")\n",
    "        return memory\n",
    "\n",
    "    def _create_advanced_prompts(self):\n",
    "        \"\"\"Create sophisticated prompt templates for different conversation contexts\"\"\"\n",
    "        print(f\"  üìù Creating Advanced Prompt Templates\")\n",
    "\n",
    "        # General Q&A Template\n",
    "        qa_template = \"\"\"\n",
    "        You are an intelligent AI assistant with access to a comprehensive knowledge base.\n",
    "        Use the following context information to provide accurate, helpful, and detailed answers.\n",
    "        \n",
    "        Context Information:\n",
    "        {context}\n",
    "        \n",
    "        Conversation History:\n",
    "        {chat_history}\n",
    "        \n",
    "        Current Question: {question}\n",
    "        \n",
    "        Instructions:\n",
    "        1. Provide accurate answers based on the context provided\n",
    "        2. If the information isn't in the context, clearly state this\n",
    "        3. Be conversational and helpful\n",
    "        4. Reference specific parts of the context when relevant\n",
    "        5. Ask clarifying questions if the query is ambiguous\n",
    "        \n",
    "        Comprehensive Answer:\n",
    "        \"\"\"\n",
    "\n",
    "        # Technical Documentation Template\n",
    "        technical_template = \"\"\"\n",
    "        You are a technical documentation expert assistant.\n",
    "        \n",
    "        Context: {context}\n",
    "        History: {chat_history}\n",
    "        Question: {question}\n",
    "        \n",
    "        Provide a detailed technical response including:\n",
    "        - Step-by-step explanations\n",
    "        - Code examples if applicable\n",
    "        - Best practices\n",
    "        - Potential pitfalls to avoid\n",
    "        \n",
    "        Technical Response:\n",
    "        \"\"\"\n",
    "\n",
    "        # Customer Service Template\n",
    "        support_template = \"\"\"\n",
    "        You are a helpful customer service representative.\n",
    "        \n",
    "        Knowledge Base: {context}\n",
    "        Previous Conversation: {chat_history}\n",
    "        Customer Query: {question}\n",
    "        \n",
    "        Provide a professional, empathetic response that:\n",
    "        - Addresses the customer's concern directly\n",
    "        - Offers practical solutions\n",
    "        - Maintains a friendly, professional tone\n",
    "        - Escalates when necessary\n",
    "        \n",
    "        Support Response:\n",
    "        \"\"\"\n",
    "\n",
    "        templates = {\n",
    "            \"general\": PromptTemplate(\n",
    "                template=qa_template,\n",
    "                input_variables=[\"context\", \"chat_history\", \"question\"],\n",
    "            ),\n",
    "            \"technical\": PromptTemplate(\n",
    "                template=technical_template,\n",
    "                input_variables=[\"context\", \"chat_history\", \"question\"],\n",
    "            ),\n",
    "            \"support\": PromptTemplate(\n",
    "                template=support_template,\n",
    "                input_variables=[\"context\", \"chat_history\", \"question\"],\n",
    "            ),\n",
    "        }\n",
    "\n",
    "        print(f\"    ‚úÖ Created {len(templates)} Prompt Templates\")\n",
    "        return templates\n",
    "\n",
    "    def create_advanced_qa_chain(\n",
    "        self,\n",
    "        conversation_id=\"default\",\n",
    "        chain_type=\"stuff\",\n",
    "        template_type=\"general\",\n",
    "        search_kwargs=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Create an advanced Q&A chain with sophisticated retrieval and conversation management\n",
    "\n",
    "        Args:\n",
    "            conversation_id: Unique identifier for the conversation\n",
    "            chain_type: Type of document combination (\"stuff\", \"map_reduce\", \"refine\")\n",
    "            template_type: Type of prompt template to use\n",
    "            search_kwargs: Advanced search parameters\n",
    "\n",
    "        Returns:\n",
    "            Configured conversational retrieval chain\n",
    "        \"\"\"\n",
    "        print(f\"\\nüîó Creating Advanced Q&A Chain\")\n",
    "        print(f\"  üÜî Conversation ID: {conversation_id}\")\n",
    "        print(f\"  üîç Chain Type: {chain_type}\")\n",
    "        print(f\"  üìù Template Type: {template_type}\")\n",
    "\n",
    "        if not self.vectorstore:\n",
    "            raise ValueError(\n",
    "                \"No vector store available. Please create a knowledge base first.\"\n",
    "            )\n",
    "\n",
    "        # Advanced search configuration\n",
    "        if search_kwargs is None:\n",
    "            search_kwargs = {\n",
    "                \"k\": 5,  # Number of documents to retrieve\n",
    "                \"score_threshold\": 0.7,  # Minimum similarity score\n",
    "                \"fetch_k\": 20,  # Number of documents to fetch before filtering\n",
    "            }\n",
    "\n",
    "        print(f\"  üîç Search Configuration: {search_kwargs}\")\n",
    "\n",
    "        # Create retriever with advanced search\n",
    "        retriever = self.vectorstore.as_retriever(\n",
    "            search_type=\"similarity_score_threshold\", search_kwargs=search_kwargs\n",
    "        )\n",
    "\n",
    "        # Get the appropriate prompt template\n",
    "        prompt_template = self.prompt_templates.get(\n",
    "            template_type, self.prompt_templates[\"general\"]\n",
    "        )\n",
    "\n",
    "        # Create conversation memory for this specific conversation\n",
    "        conversation_memory = ConversationBufferMemory(\n",
    "            memory_key=\"chat_history\", return_messages=True, output_key=\"answer\"\n",
    "        )\n",
    "\n",
    "        # Create the conversational retrieval chain\n",
    "        qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "            llm=self.llm,\n",
    "            retriever=retriever,\n",
    "            memory=conversation_memory,\n",
    "            return_source_documents=True,\n",
    "            chain_type=chain_type,\n",
    "            combine_docs_chain_kwargs={\"prompt\": prompt_template},\n",
    "            verbose=True,  # Enable detailed logging\n",
    "        )\n",
    "\n",
    "        # Store the chain and initialize conversation tracking\n",
    "        self.conversation_chains[conversation_id] = qa_chain\n",
    "        self.conversation_histories[conversation_id] = []\n",
    "        self.system_stats[conversation_id] = {\n",
    "            \"created_at\": datetime.now().isoformat(),\n",
    "            \"total_interactions\": 0,\n",
    "            \"avg_response_time\": 0,\n",
    "            \"template_type\": template_type,\n",
    "            \"chain_type\": chain_type,\n",
    "        }\n",
    "\n",
    "        print(f\"  ‚úÖ Advanced Q&A Chain Created Successfully!\")\n",
    "        print(f\"    üîó Chain ID: {conversation_id}\")\n",
    "        print(f\"    üß† Memory: {type(conversation_memory).__name__}\")\n",
    "        print(f\"    üîç Retriever: Advanced Similarity Search\")\n",
    "\n",
    "        return qa_chain\n",
    "\n",
    "    def ask_intelligent_question(\n",
    "        self, question, conversation_id=\"default\", include_sources=True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Ask an intelligent question with advanced processing and context management\n",
    "\n",
    "        Args:\n",
    "            question: The question to ask\n",
    "            conversation_id: ID of the conversation chain to use\n",
    "            include_sources: Whether to include source documents in response\n",
    "\n",
    "        Returns:\n",
    "            Dictionary with answer, sources, and metadata\n",
    "        \"\"\"\n",
    "        print(f\"\\nüí¨ Processing Intelligent Query\")\n",
    "        print(f\"  üÜî Conversation: {conversation_id}\")\n",
    "        print(f\"  ‚ùì Question: {question[:100]}{'...' if len(question) > 100 else ''}\")\n",
    "\n",
    "        start_time = datetime.now()\n",
    "\n",
    "        # Get or create the conversation chain\n",
    "        if conversation_id not in self.conversation_chains:\n",
    "            print(f\"  üîÑ Creating new conversation chain...\")\n",
    "            self.create_advanced_qa_chain(conversation_id)\n",
    "\n",
    "        qa_chain = self.conversation_chains[conversation_id]\n",
    "\n",
    "        try:\n",
    "            # Process the question through the chain\n",
    "            print(f\"  ü§ñ Generating Response...\")\n",
    "\n",
    "            result = qa_chain(\n",
    "                {\n",
    "                    \"question\": question,\n",
    "                    \"chat_history\": self.conversation_histories[conversation_id],\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Calculate response time\n",
    "            response_time = (datetime.now() - start_time).total_seconds()\n",
    "\n",
    "            # Update conversation history\n",
    "            self.conversation_histories[conversation_id].append(\n",
    "                (question, result[\"answer\"])\n",
    "            )\n",
    "\n",
    "            # Maintain conversation history limit\n",
    "            if (\n",
    "                len(self.conversation_histories[conversation_id])\n",
    "                > self.max_conversation_history\n",
    "            ):\n",
    "                self.conversation_histories[conversation_id] = (\n",
    "                    self.conversation_histories[conversation_id][\n",
    "                        -self.max_conversation_history :\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "            # Update statistics\n",
    "            stats = self.system_stats[conversation_id]\n",
    "            stats[\"total_interactions\"] += 1\n",
    "            stats[\"avg_response_time\"] = (\n",
    "                stats[\"avg_response_time\"] * (stats[\"total_interactions\"] - 1)\n",
    "                + response_time\n",
    "            ) / stats[\"total_interactions\"]\n",
    "            stats[\"last_interaction\"] = datetime.now().isoformat()\n",
    "\n",
    "            # Prepare response\n",
    "            response = {\n",
    "                \"answer\": result[\"answer\"],\n",
    "                \"question\": question,\n",
    "                \"conversation_id\": conversation_id,\n",
    "                \"response_time\": response_time,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "            }\n",
    "\n",
    "            # Add source documents if requested\n",
    "            if include_sources and \"source_documents\" in result:\n",
    "                sources = []\n",
    "                for i, doc in enumerate(result[\"source_documents\"]):\n",
    "                    source_info = {\n",
    "                        \"content\": doc.page_content[:300] + \"...\"\n",
    "                        if len(doc.page_content) > 300\n",
    "                        else doc.page_content,\n",
    "                        \"metadata\": doc.metadata,\n",
    "                        \"relevance_rank\": i + 1,\n",
    "                    }\n",
    "                    sources.append(source_info)\n",
    "\n",
    "                response[\"sources\"] = sources\n",
    "                response[\"source_count\"] = len(sources)\n",
    "\n",
    "            print(f\"  ‚úÖ Response Generated Successfully!\")\n",
    "            print(f\"    ‚è±Ô∏è Response Time: {response_time:.2f} seconds\")\n",
    "            print(f\"    üìö Sources Used: {len(result.get('source_documents', []))}\")\n",
    "            print(f\"    üìä Total Interactions: {stats['total_interactions']}\")\n",
    "\n",
    "            return response\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error processing question: {str(e)}\"\n",
    "            logger.error(error_msg)\n",
    "\n",
    "            return {\n",
    "                \"answer\": \"I apologize, but I encountered an error processing your question. Please try rephrasing or contact support.\",\n",
    "                \"error\": error_msg,\n",
    "                \"question\": question,\n",
    "                \"conversation_id\": conversation_id,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "            }\n",
    "\n",
    "    def get_conversation_summary(self, conversation_id=\"default\"):\n",
    "        \"\"\"Get comprehensive statistics and summary for a conversation\"\"\"\n",
    "        if conversation_id not in self.system_stats:\n",
    "            return {\"error\": f\"Conversation {conversation_id} not found\"}\n",
    "\n",
    "        stats = self.system_stats[conversation_id]\n",
    "        history = self.conversation_histories.get(conversation_id, [])\n",
    "\n",
    "        return {\n",
    "            \"conversation_id\": conversation_id,\n",
    "            \"statistics\": stats,\n",
    "            \"conversation_length\": len(history),\n",
    "            \"recent_questions\": [q for q, a in history[-3:]],  # Last 3 questions\n",
    "        }\n",
    "\n",
    "\n",
    "# Initialize the Advanced Conversational AI System\n",
    "print(f\"\\nü§ñ Initializing Advanced Conversational AI...\")\n",
    "\n",
    "# Create the conversational AI instance\n",
    "conversational_ai = AdvancedConversationalAI(\n",
    "    vectorstore=None,  # Will be set after knowledge base creation\n",
    "    llm_type=\"openai\",  # Change to \"huggingface\" for local inference\n",
    "    conversation_memory_type=\"buffer\",\n",
    "    max_conversation_history=15,\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Advanced Conversational AI System Initialized!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Example usage (uncommented when vector store is available):\n",
    "# conversational_ai.vectorstore = kb_manager.knowledge_bases.get(\"company_docs\")\n",
    "# qa_chain = conversational_ai.create_advanced_qa_chain(\n",
    "#     conversation_id=\"demo_conversation\",\n",
    "#     template_type=\"general\"\n",
    "# )\n",
    "#\n",
    "# response = conversational_ai.ask_intelligent_question(\n",
    "#     \"What are the main features of our product?\",\n",
    "#     conversation_id=\"demo_conversation\"\n",
    "# )\n",
    "# print(f\"Answer: {response['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83990ef",
   "metadata": {},
   "source": [
    "### üåê Interactive Streamlit Application Interface\n",
    "\n",
    "Our sophisticated Streamlit application provides a user-friendly interface for both the multimodal AI system and the RAG-powered chatbot. The interface includes:\n",
    "\n",
    "- **üéØ Dual-Mode Operation**: Seamlessly switch between multimodal prediction and intelligent chatbot\n",
    "- **üìä Advanced Analytics Dashboard**: Real-time performance metrics and conversation analytics\n",
    "- **üîÑ Session Management**: Persistent conversation history and context preservation\n",
    "- **üìÅ Dynamic Knowledge Base Management**: Upload and manage documents in real-time\n",
    "- **üé® Professional UI/UX**: Modern, responsive design with intuitive navigation\n",
    "- **‚ö° Real-time Processing**: Instant responses with progress indicators and status updates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ffc6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COMPREHENSIVE SYSTEM DEMONSTRATION & TESTING SUITE\n",
    "# =============================================================================\n",
    "\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class AdvancedSystemDemo:\n",
    "    \"\"\"\n",
    "    Comprehensive demonstration and testing suite for the multimodal AI system\n",
    "    and RAG-powered chatbot integration\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_processor=None,\n",
    "        model_architect=None,\n",
    "        kb_manager=None,\n",
    "        conversational_ai=None,\n",
    "    ):\n",
    "        self.data_processor = data_processor\n",
    "        self.model_architect = model_architect\n",
    "        self.kb_manager = kb_manager\n",
    "        self.conversational_ai = conversational_ai\n",
    "        self.demo_results = {}\n",
    "\n",
    "        print(\"üé¨ Advanced System Demo Suite Initialized\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "    def demonstrate_multimodal_prediction(self, sample_data=None):\n",
    "        \"\"\"\n",
    "        Demonstrate the multimodal AI prediction capabilities with comprehensive examples\n",
    "        \"\"\"\n",
    "        print(\"\\nüéØ MULTIMODAL AI PREDICTION DEMONSTRATION\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        if not self.data_processor or not self.model_architect:\n",
    "            print(\"‚ö†Ô∏è Multimodal components not available for demonstration\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            # Generate or use sample data\n",
    "            if sample_data is None:\n",
    "                print(\"  üìä Generating synthetic demonstration data...\")\n",
    "\n",
    "                # Create synthetic multimodal data\n",
    "                np.random.seed(42)  # For reproducible results\n",
    "\n",
    "                sample_data = {\n",
    "                    \"image_data\": np.random.rand(224, 224, 3),  # Synthetic image\n",
    "                    \"tabular_data\": np.random.rand(10),  # Synthetic features\n",
    "                    \"metadata\": {\n",
    "                        \"source\": \"synthetic_demo\",\n",
    "                        \"timestamp\": datetime.now().isoformat(),\n",
    "                        \"data_type\": \"demonstration\",\n",
    "                    },\n",
    "                }\n",
    "\n",
    "                print(f\"    ‚úÖ Synthetic data generated:\")\n",
    "                print(f\"       üñºÔ∏è Image shape: {sample_data['image_data'].shape}\")\n",
    "                print(f\"       üìä Tabular features: {len(sample_data['tabular_data'])}\")\n",
    "\n",
    "            # Preprocess the data\n",
    "            print(\"  üîÑ Preprocessing demonstration data...\")\n",
    "            processed_data = self.data_processor.preprocess_demonstration_data(\n",
    "                sample_data\n",
    "            )\n",
    "\n",
    "            # Make prediction\n",
    "            print(\"  ü§ñ Generating multimodal prediction...\")\n",
    "            start_time = time.time()\n",
    "\n",
    "            prediction_result = self.model_architect.predict_with_confidence(\n",
    "                processed_data[\"image_features\"],\n",
    "                processed_data[\"tabular_features\"],\n",
    "                return_probabilities=True,\n",
    "                include_attention_maps=True,\n",
    "            )\n",
    "\n",
    "            processing_time = time.time() - start_time\n",
    "\n",
    "            # Display results\n",
    "            print(f\"  ‚úÖ Prediction completed in {processing_time:.3f} seconds\")\n",
    "            print(\n",
    "                f\"    üéØ Predicted Class: {prediction_result.get('predicted_class', 'N/A')}\"\n",
    "            )\n",
    "            print(\n",
    "                f\"    üìä Confidence Score: {prediction_result.get('confidence', 0):.3f}\"\n",
    "            )\n",
    "            print(f\"    üîç Top 3 Probabilities:\")\n",
    "\n",
    "            if \"probabilities\" in prediction_result:\n",
    "                top_probs = sorted(\n",
    "                    prediction_result[\"probabilities\"].items(),\n",
    "                    key=lambda x: x[1],\n",
    "                    reverse=True,\n",
    "                )[:3]\n",
    "                for i, (class_name, prob) in enumerate(top_probs, 1):\n",
    "                    print(f\"       {i}. {class_name}: {prob:.3f}\")\n",
    "\n",
    "            # Store demo results\n",
    "            self.demo_results[\"multimodal_prediction\"] = {\n",
    "                \"success\": True,\n",
    "                \"processing_time\": processing_time,\n",
    "                \"prediction\": prediction_result,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "            }\n",
    "\n",
    "            return prediction_result\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Multimodal prediction demo failed: {str(e)}\"\n",
    "            print(f\"  ‚ùå {error_msg}\")\n",
    "\n",
    "            self.demo_results[\"multimodal_prediction\"] = {\n",
    "                \"success\": False,\n",
    "                \"error\": error_msg,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "            }\n",
    "\n",
    "            return None\n",
    "\n",
    "    def demonstrate_chatbot_capabilities(self, demo_questions=None):\n",
    "        \"\"\"\n",
    "        Demonstrate the RAG-powered chatbot with various question types and scenarios\n",
    "        \"\"\"\n",
    "        print(\"\\nü§ñ RAG-POWERED CHATBOT DEMONSTRATION\")\n",
    "        print(\"-\" * 45)\n",
    "\n",
    "        if not self.conversational_ai:\n",
    "            print(\"‚ö†Ô∏è Conversational AI not available for demonstration\")\n",
    "            return None\n",
    "\n",
    "        # Default demo questions covering various scenarios\n",
    "        if demo_questions is None:\n",
    "            demo_questions = [\n",
    "                {\n",
    "                    \"question\": \"What are the key features of this multimodal AI system?\",\n",
    "                    \"category\": \"technical_overview\",\n",
    "                    \"expected_context\": \"system capabilities\",\n",
    "                },\n",
    "                {\n",
    "                    \"question\": \"How does the RAG (Retrieval Augmented Generation) approach work?\",\n",
    "                    \"category\": \"technical_deep_dive\",\n",
    "                    \"expected_context\": \"RAG methodology\",\n",
    "                },\n",
    "                {\n",
    "                    \"question\": \"Can you explain the model architecture used for multimodal learning?\",\n",
    "                    \"category\": \"architecture_inquiry\",\n",
    "                    \"expected_context\": \"neural network design\",\n",
    "                },\n",
    "                {\n",
    "                    \"question\": \"What are the benefits of combining computer vision with tabular data?\",\n",
    "                    \"category\": \"methodology_question\",\n",
    "                    \"expected_context\": \"multimodal advantages\",\n",
    "                },\n",
    "            ]\n",
    "\n",
    "        print(f\"  üí¨ Testing {len(demo_questions)} demonstration scenarios...\")\n",
    "\n",
    "        conversation_results = []\n",
    "        conversation_id = f\"demo_session_{int(time.time())}\"\n",
    "\n",
    "        for i, demo in enumerate(demo_questions, 1):\n",
    "            print(f\"\\n  üìù Demo Question {i}/{len(demo_questions)}\")\n",
    "            print(f\"     Category: {demo['category']}\")\n",
    "            print(\n",
    "                f\"     Question: {demo['question'][:80]}{'...' if len(demo['question']) > 80 else ''}\"\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                # Process the question\n",
    "                start_time = time.time()\n",
    "\n",
    "                response = self.conversational_ai.ask_intelligent_question(\n",
    "                    question=demo[\"question\"],\n",
    "                    conversation_id=conversation_id,\n",
    "                    include_sources=True,\n",
    "                )\n",
    "\n",
    "                processing_time = time.time() - start_time\n",
    "\n",
    "                # Analyze response quality\n",
    "                response_analysis = self._analyze_response_quality(response, demo)\n",
    "\n",
    "                print(f\"     ‚è±Ô∏è Response Time: {processing_time:.2f}s\")\n",
    "                print(\n",
    "                    f\"     üìä Quality Score: {response_analysis['quality_score']:.2f}/5.0\"\n",
    "                )\n",
    "                print(f\"     üìö Sources Used: {response.get('source_count', 0)}\")\n",
    "                print(\n",
    "                    f\"     üí¨ Response Length: {len(response.get('answer', ''))} chars\"\n",
    "                )\n",
    "\n",
    "                # Store results\n",
    "                conversation_results.append(\n",
    "                    {\n",
    "                        \"question_number\": i,\n",
    "                        \"question\": demo[\"question\"],\n",
    "                        \"category\": demo[\"category\"],\n",
    "                        \"response\": response,\n",
    "                        \"processing_time\": processing_time,\n",
    "                        \"quality_analysis\": response_analysis,\n",
    "                        \"timestamp\": datetime.now().isoformat(),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                # Brief delay between questions for realistic demonstration\n",
    "                time.sleep(0.5)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"     ‚ùå Error: {str(e)}\")\n",
    "                conversation_results.append(\n",
    "                    {\n",
    "                        \"question_number\": i,\n",
    "                        \"question\": demo[\"question\"],\n",
    "                        \"error\": str(e),\n",
    "                        \"timestamp\": datetime.now().isoformat(),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        # Generate conversation summary\n",
    "        conversation_summary = self._generate_conversation_summary(conversation_results)\n",
    "\n",
    "        print(f\"\\n  üìä CHATBOT DEMONSTRATION SUMMARY\")\n",
    "        print(f\"     üí¨ Total Questions: {len(demo_questions)}\")\n",
    "        print(\n",
    "            f\"     ‚úÖ Successful Responses: {conversation_summary['successful_responses']}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"     ‚è±Ô∏è Average Response Time: {conversation_summary['avg_response_time']:.2f}s\"\n",
    "        )\n",
    "        print(\n",
    "            f\"     üìä Average Quality Score: {conversation_summary['avg_quality_score']:.2f}/5.0\"\n",
    "        )\n",
    "        print(f\"     üîó Conversation ID: {conversation_id}\")\n",
    "\n",
    "        # Store demo results\n",
    "        self.demo_results[\"chatbot_demo\"] = {\n",
    "            \"conversation_id\": conversation_id,\n",
    "            \"results\": conversation_results,\n",
    "            \"summary\": conversation_summary,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "        }\n",
    "\n",
    "        return conversation_results\n",
    "\n",
    "    def _analyze_response_quality(self, response, demo_context):\n",
    "        \"\"\"\n",
    "        Analyze the quality of a chatbot response based on various criteria\n",
    "        \"\"\"\n",
    "        quality_metrics = {\n",
    "            \"response_completeness\": 0,\n",
    "            \"source_utilization\": 0,\n",
    "            \"relevance_score\": 0,\n",
    "            \"technical_accuracy\": 0,\n",
    "            \"conversational_flow\": 0,\n",
    "        }\n",
    "\n",
    "        answer = response.get(\"answer\", \"\")\n",
    "        sources = response.get(\"sources\", [])\n",
    "\n",
    "        # Response completeness (based on length and structure)\n",
    "        if len(answer) > 100:\n",
    "            quality_metrics[\"response_completeness\"] = min(5.0, len(answer) / 200)\n",
    "\n",
    "        # Source utilization\n",
    "        if sources:\n",
    "            quality_metrics[\"source_utilization\"] = min(5.0, len(sources))\n",
    "\n",
    "        # Relevance score (basic keyword matching with demo context)\n",
    "        expected_context = demo_context.get(\"expected_context\", \"\").lower()\n",
    "        if expected_context and expected_context in answer.lower():\n",
    "            quality_metrics[\"relevance_score\"] = 4.0\n",
    "        elif any(word in answer.lower() for word in expected_context.split()):\n",
    "            quality_metrics[\"relevance_score\"] = 2.5\n",
    "\n",
    "        # Technical accuracy (presence of technical terms)\n",
    "        technical_terms = [\n",
    "            \"model\",\n",
    "            \"algorithm\",\n",
    "            \"neural\",\n",
    "            \"learning\",\n",
    "            \"data\",\n",
    "            \"system\",\n",
    "            \"architecture\",\n",
    "        ]\n",
    "        found_terms = sum(1 for term in technical_terms if term in answer.lower())\n",
    "        quality_metrics[\"technical_accuracy\"] = min(5.0, found_terms)\n",
    "\n",
    "        # Conversational flow (proper sentence structure)\n",
    "        sentences = answer.split(\".\")\n",
    "        if len(sentences) > 2:\n",
    "            quality_metrics[\"conversational_flow\"] = 4.0\n",
    "\n",
    "        # Calculate overall quality score\n",
    "        overall_score = np.mean(list(quality_metrics.values()))\n",
    "\n",
    "        return {\n",
    "            \"quality_score\": overall_score,\n",
    "            \"detailed_metrics\": quality_metrics,\n",
    "            \"analysis_timestamp\": datetime.now().isoformat(),\n",
    "        }\n",
    "\n",
    "    def _generate_conversation_summary(self, conversation_results):\n",
    "        \"\"\"\n",
    "        Generate comprehensive summary of conversation demonstration\n",
    "        \"\"\"\n",
    "        successful_results = [r for r in conversation_results if \"error\" not in r]\n",
    "\n",
    "        summary = {\n",
    "            \"total_questions\": len(conversation_results),\n",
    "            \"successful_responses\": len(successful_results),\n",
    "            \"failed_responses\": len(conversation_results) - len(successful_results),\n",
    "            \"success_rate\": len(successful_results) / len(conversation_results)\n",
    "            if conversation_results\n",
    "            else 0,\n",
    "        }\n",
    "\n",
    "        if successful_results:\n",
    "            response_times = [r[\"processing_time\"] for r in successful_results]\n",
    "            quality_scores = [\n",
    "                r[\"quality_analysis\"][\"quality_score\"] for r in successful_results\n",
    "            ]\n",
    "\n",
    "            summary.update(\n",
    "                {\n",
    "                    \"avg_response_time\": np.mean(response_times),\n",
    "                    \"min_response_time\": min(response_times),\n",
    "                    \"max_response_time\": max(response_times),\n",
    "                    \"avg_quality_score\": np.mean(quality_scores),\n",
    "                    \"best_quality_score\": max(quality_scores),\n",
    "                    \"worst_quality_score\": min(quality_scores),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return summary\n",
    "\n",
    "    def run_comprehensive_demo(self):\n",
    "        \"\"\"\n",
    "        Run a complete demonstration of both multimodal AI and chatbot capabilities\n",
    "        \"\"\"\n",
    "        print(\"\\nüé¨ COMPREHENSIVE SYSTEM DEMONSTRATION\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"üïê Demo Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "        demo_start_time = time.time()\n",
    "\n",
    "        # Part 1: Multimodal AI Demonstration\n",
    "        print(\"\\nüìç PHASE 1: Multimodal AI System\")\n",
    "        multimodal_result = self.demonstrate_multimodal_prediction()\n",
    "\n",
    "        # Part 2: Chatbot Demonstration\n",
    "        print(\"\\nüìç PHASE 2: RAG-Powered Chatbot\")\n",
    "        chatbot_result = self.demonstrate_chatbot_capabilities()\n",
    "\n",
    "        # Part 3: Integration Test (if both systems are available)\n",
    "        if multimodal_result and chatbot_result:\n",
    "            print(\"\\nüìç PHASE 3: System Integration Test\")\n",
    "            self._demonstrate_system_integration()\n",
    "\n",
    "        total_demo_time = time.time() - demo_start_time\n",
    "\n",
    "        # Generate final report\n",
    "        self._generate_demo_report(total_demo_time)\n",
    "\n",
    "        print(f\"\\nüéâ COMPREHENSIVE DEMO COMPLETED\")\n",
    "        print(f\"‚è±Ô∏è Total Demo Time: {total_demo_time:.2f} seconds\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        return self.demo_results\n",
    "\n",
    "    def _demonstrate_system_integration(self):\n",
    "        \"\"\"\n",
    "        Demonstrate integration between multimodal AI and chatbot systems\n",
    "        \"\"\"\n",
    "        print(\"  üîó Testing System Integration...\")\n",
    "\n",
    "        integration_questions = [\n",
    "            \"How can I interpret the multimodal prediction results?\",\n",
    "            \"What should I do if the confidence score is low?\",\n",
    "            \"Can you explain how the image and tabular data are combined?\",\n",
    "        ]\n",
    "\n",
    "        print(\n",
    "            f\"    üí¨ Processing {len(integration_questions)} integration questions...\"\n",
    "        )\n",
    "\n",
    "        for question in integration_questions:\n",
    "            try:\n",
    "                response = self.conversational_ai.ask_intelligent_question(\n",
    "                    question=question, conversation_id=\"integration_test\"\n",
    "                )\n",
    "                print(f\"    ‚úÖ Integration test passed for: {question[:40]}...\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"    ‚ùå Integration test failed: {str(e)}\")\n",
    "\n",
    "    def _generate_demo_report(self, total_time):\n",
    "        \"\"\"\n",
    "        Generate comprehensive demonstration report\n",
    "        \"\"\"\n",
    "        print(f\"\\nüìä DEMONSTRATION REPORT\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        # System availability\n",
    "        systems_available = {\n",
    "            \"Multimodal AI\": self.data_processor is not None\n",
    "            and self.model_architect is not None,\n",
    "            \"RAG Chatbot\": self.conversational_ai is not None,\n",
    "            \"Knowledge Base\": self.kb_manager is not None,\n",
    "        }\n",
    "\n",
    "        print(f\"  üîß System Availability:\")\n",
    "        for system, available in systems_available.items():\n",
    "            status = \"‚úÖ Available\" if available else \"‚ùå Not Available\"\n",
    "            print(f\"     {system}: {status}\")\n",
    "\n",
    "        # Performance summary\n",
    "        if \"multimodal_prediction\" in self.demo_results:\n",
    "            ml_result = self.demo_results[\"multimodal_prediction\"]\n",
    "            if ml_result[\"success\"]:\n",
    "                print(f\"  üéØ Multimodal AI Performance:\")\n",
    "                print(f\"     Processing Time: {ml_result['processing_time']:.3f}s\")\n",
    "                print(\n",
    "                    f\"     Prediction Confidence: {ml_result['prediction'].get('confidence', 'N/A')}\"\n",
    "                )\n",
    "\n",
    "        if \"chatbot_demo\" in self.demo_results:\n",
    "            chatbot_summary = self.demo_results[\"chatbot_demo\"][\"summary\"]\n",
    "            print(f\"  ü§ñ Chatbot Performance:\")\n",
    "            print(f\"     Success Rate: {chatbot_summary['success_rate']:.1%}\")\n",
    "            print(\n",
    "                f\"     Avg Response Time: {chatbot_summary.get('avg_response_time', 0):.2f}s\"\n",
    "            )\n",
    "            print(\n",
    "                f\"     Avg Quality Score: {chatbot_summary.get('avg_quality_score', 0):.2f}/5.0\"\n",
    "            )\n",
    "\n",
    "        print(f\"  ‚è±Ô∏è Total Demo Duration: {total_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "# Initialize the Advanced Demo System\n",
    "print(\"\\nüé¨ Initializing Comprehensive Demo Suite...\")\n",
    "\n",
    "demo_suite = AdvancedSystemDemo(\n",
    "    data_processor=globals().get(\"data_processor\"),\n",
    "    model_architect=globals().get(\"model_architect\"),\n",
    "    kb_manager=globals().get(\"kb_manager\"),\n",
    "    conversational_ai=globals().get(\"conversational_ai\"),\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Demo Suite Ready for Comprehensive Testing!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Example comprehensive demo execution (uncomment to run):\n",
    "# print(\"\\nüöÄ Starting Comprehensive System Demonstration...\")\n",
    "# demo_results = demo_suite.run_comprehensive_demo()\n",
    "#\n",
    "# print(\"\\nüìã Demo Results Summary:\")\n",
    "# for phase, results in demo_results.items():\n",
    "#     print(f\"  {phase}: {'‚úÖ Success' if results.get('success', True) else '‚ùå Failed'}\")\n",
    "\n",
    "# Quick individual demonstrations (uncomment as needed):\n",
    "# multimodal_demo = demo_suite.demonstrate_multimodal_prediction()\n",
    "# chatbot_demo = demo_suite.demonstrate_chatbot_capabilities()\n",
    "\n",
    "print(\"\\nüí° Demo Instructions:\")\n",
    "print(\"  1. Uncomment the demonstration lines above to run specific tests\")\n",
    "print(\"  2. Ensure all required components are properly initialized\")\n",
    "print(\"  3. Check the demo_results for detailed performance metrics\")\n",
    "print(\"  4. Review the comprehensive report for system integration status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88231881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ADVANCED STREAMLIT APPLICATION - MULTIMODAL AI & RAG CHATBOT INTERFACE\n",
    "# =============================================================================\n",
    "\n",
    "import streamlit as st\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "import io\n",
    "import base64\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "# Configure Streamlit page\n",
    "st.set_page_config(\n",
    "    page_title=\"ü§ñ Advanced AI System Suite\",\n",
    "    page_icon=\"ü§ñ\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\",\n",
    ")\n",
    "\n",
    "# Custom CSS for enhanced styling\n",
    "st.markdown(\n",
    "    \"\"\"\n",
    "<style>\n",
    "    .main-header {\n",
    "        font-size: 3rem;\n",
    "        font-weight: bold;\n",
    "        color: #1e88e5;\n",
    "        text-align: center;\n",
    "        margin-bottom: 2rem;\n",
    "        background: linear-gradient(90deg, #1e88e5, #43a047);\n",
    "        -webkit-background-clip: text;\n",
    "        -webkit-text-fill-color: transparent;\n",
    "    }\n",
    "    .metric-card {\n",
    "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "        padding: 1rem;\n",
    "        border-radius: 10px;\n",
    "        color: white;\n",
    "        text-align: center;\n",
    "        margin: 0.5rem 0;\n",
    "    }\n",
    "    .success-box {\n",
    "        background-color: #d4edda;\n",
    "        border: 1px solid #c3e6cb;\n",
    "        border-radius: 5px;\n",
    "        padding: 1rem;\n",
    "        margin: 1rem 0;\n",
    "    }\n",
    "    .warning-box {\n",
    "        background-color: #fff3cd;\n",
    "        border: 1px solid #ffeaa7;\n",
    "        border-radius: 5px;\n",
    "        padding: 1rem;\n",
    "        margin: 1rem 0;\n",
    "    }\n",
    "    .info-box {\n",
    "        background-color: #e7f3ff;\n",
    "        border: 1px solid #b8daff;\n",
    "        border-radius: 5px;\n",
    "        padding: 1rem;\n",
    "        margin: 1rem 0;\n",
    "    }\n",
    "</style>\n",
    "\"\"\",\n",
    "    unsafe_allow_html=True,\n",
    ")\n",
    "\n",
    "\n",
    "class AdvancedStreamlitApp:\n",
    "    \"\"\"\n",
    "    Sophisticated Streamlit application providing comprehensive interface for\n",
    "    multimodal AI predictions and RAG-powered conversational AI\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.initialize_session_state()\n",
    "        self.app_version = \"3.1.0\"\n",
    "        self.last_update = \"2024-01-15\"\n",
    "\n",
    "    def initialize_session_state(self):\n",
    "        \"\"\"Initialize session state variables for persistent data management\"\"\"\n",
    "        if \"conversation_history\" not in st.session_state:\n",
    "            st.session_state.conversation_history = []\n",
    "\n",
    "        if \"prediction_results\" not in st.session_state:\n",
    "            st.session_state.prediction_results = []\n",
    "\n",
    "        if \"system_stats\" not in st.session_state:\n",
    "            st.session_state.system_stats = {\n",
    "                \"total_predictions\": 0,\n",
    "                \"total_conversations\": 0,\n",
    "                \"avg_confidence\": 0,\n",
    "                \"session_start\": datetime.now(),\n",
    "            }\n",
    "\n",
    "        if \"current_conversation_id\" not in st.session_state:\n",
    "            st.session_state.current_conversation_id = f\"session_{int(time.time())}\"\n",
    "\n",
    "        if \"knowledge_bases\" not in st.session_state:\n",
    "            st.session_state.knowledge_bases = []\n",
    "\n",
    "    def render_header(self):\n",
    "        \"\"\"Render the application header with branding and navigation\"\"\"\n",
    "        st.markdown(\n",
    "            '<h1 class=\"main-header\">ü§ñ Advanced AI System Suite</h1>',\n",
    "            unsafe_allow_html=True,\n",
    "        )\n",
    "\n",
    "        col1, col2, col3 = st.columns([1, 2, 1])\n",
    "        with col2:\n",
    "            st.markdown(\n",
    "                f\"\"\"\n",
    "            <div style=\"text-align: center; color: #666;\">\n",
    "                <p><strong>Version {self.app_version}</strong> | Last Updated: {self.last_update}</p>\n",
    "                <p>üéØ Multimodal AI Predictions + ü§ñ RAG-Powered Conversational Intelligence</p>\n",
    "            </div>\n",
    "            \"\"\",\n",
    "                unsafe_allow_html=True,\n",
    "            )\n",
    "\n",
    "        st.markdown(\"---\")\n",
    "\n",
    "    def render_sidebar(self):\n",
    "        \"\"\"Render advanced sidebar with system controls and monitoring\"\"\"\n",
    "        with st.sidebar:\n",
    "            st.header(\"üîß System Control Panel\")\n",
    "\n",
    "            # System Status\n",
    "            st.subheader(\"üìä System Status\")\n",
    "\n",
    "            # Mock system status (replace with actual system checks)\n",
    "            system_status = {\n",
    "                \"ü§ñ Multimodal AI\": \"‚úÖ Online\",\n",
    "                \"üí¨ RAG Chatbot\": \"‚úÖ Online\",\n",
    "                \"üìö Knowledge Base\": \"‚úÖ Connected\",\n",
    "                \"üîÑ Processing\": \"‚ö° Ready\",\n",
    "            }\n",
    "\n",
    "            for component, status in system_status.items():\n",
    "                st.write(f\"{component}: {status}\")\n",
    "\n",
    "            st.markdown(\"---\")\n",
    "\n",
    "            # Session Statistics\n",
    "            st.subheader(\"üìà Session Statistics\")\n",
    "            stats = st.session_state.system_stats\n",
    "\n",
    "            st.metric(\"Total Predictions\", stats[\"total_predictions\"])\n",
    "            st.metric(\"Conversations\", stats[\"total_conversations\"])\n",
    "\n",
    "            if stats[\"avg_confidence\"] > 0:\n",
    "                st.metric(\"Avg Confidence\", f\"{stats['avg_confidence']:.3f}\")\n",
    "\n",
    "            session_duration = datetime.now() - stats[\"session_start\"]\n",
    "            st.metric(\"Session Duration\", f\"{session_duration.seconds // 60}m\")\n",
    "\n",
    "            st.markdown(\"---\")\n",
    "\n",
    "            # Advanced Settings\n",
    "            st.subheader(\"‚öôÔ∏è Advanced Settings\")\n",
    "\n",
    "            confidence_threshold = st.slider(\n",
    "                \"Confidence Threshold\",\n",
    "                min_value=0.0,\n",
    "                max_value=1.0,\n",
    "                value=0.7,\n",
    "                step=0.05,\n",
    "                help=\"Minimum confidence for predictions\",\n",
    "            )\n",
    "\n",
    "            response_detail = st.selectbox(\n",
    "                \"Response Detail Level\",\n",
    "                [\"Brief\", \"Standard\", \"Detailed\"],\n",
    "                index=1,\n",
    "                help=\"Level of detail in chatbot responses\",\n",
    "            )\n",
    "\n",
    "            enable_source_display = st.checkbox(\n",
    "                \"Show Sources\",\n",
    "                value=True,\n",
    "                help=\"Display source documents in chatbot responses\",\n",
    "            )\n",
    "\n",
    "            st.markdown(\"---\")\n",
    "\n",
    "            # Data Management\n",
    "            st.subheader(\"üìÅ Data Management\")\n",
    "\n",
    "            if st.button(\"üóëÔ∏è Clear Session Data\", help=\"Clear all session data\"):\n",
    "                self.clear_session_data()\n",
    "                st.rerun()\n",
    "\n",
    "            if st.button(\"üíæ Export Session\", help=\"Export session data\"):\n",
    "                self.export_session_data()\n",
    "\n",
    "            # Knowledge Base Management\n",
    "            st.subheader(\"üìö Knowledge Base\")\n",
    "            uploaded_file = st.file_uploader(\n",
    "                \"Upload Documents\",\n",
    "                type=[\"txt\", \"pdf\", \"docx\", \"csv\"],\n",
    "                accept_multiple_files=True,\n",
    "                help=\"Upload documents to expand the knowledge base\",\n",
    "            )\n",
    "\n",
    "            if uploaded_file:\n",
    "                if st.button(\"üîÑ Process Documents\"):\n",
    "                    self.process_uploaded_documents(uploaded_file)\n",
    "\n",
    "    def render_main_interface(self):\n",
    "        \"\"\"Render the main application interface with tabbed navigation\"\"\"\n",
    "        tab1, tab2, tab3, tab4 = st.tabs(\n",
    "            [\n",
    "                \"üéØ Multimodal AI\",\n",
    "                \"üí¨ RAG Chatbot\",\n",
    "                \"üìä Analytics Dashboard\",\n",
    "                \"üìñ System Documentation\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        with tab1:\n",
    "            self.render_multimodal_interface()\n",
    "\n",
    "        with tab2:\n",
    "            self.render_chatbot_interface()\n",
    "\n",
    "        with tab3:\n",
    "            self.render_analytics_dashboard()\n",
    "\n",
    "        with tab4:\n",
    "            self.render_documentation()\n",
    "\n",
    "    def render_multimodal_interface(self):\n",
    "        \"\"\"Render the multimodal AI prediction interface\"\"\"\n",
    "        st.header(\"üéØ Advanced Multimodal AI Prediction System\")\n",
    "\n",
    "        st.markdown(\n",
    "            \"\"\"\n",
    "        <div class=\"info-box\">\n",
    "            <h4>üî¨ Multimodal AI Capabilities</h4>\n",
    "            <ul>\n",
    "                <li><strong>üñºÔ∏è Computer Vision:</strong> Advanced image analysis and feature extraction</li>\n",
    "                <li><strong>üìä Tabular Data:</strong> Structured data processing and pattern recognition</li>\n",
    "                <li><strong>üß† Fusion Architecture:</strong> Intelligent combination of multiple data modalities</li>\n",
    "                <li><strong>üìà Confidence Scoring:</strong> Reliable prediction confidence assessment</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "        \"\"\",\n",
    "            unsafe_allow_html=True,\n",
    "        )\n",
    "\n",
    "        col1, col2 = st.columns([1, 1])\n",
    "\n",
    "        with col1:\n",
    "            st.subheader(\"üñºÔ∏è Image Input\")\n",
    "\n",
    "            # Image upload options\n",
    "            image_source = st.radio(\n",
    "                \"Image Source:\",\n",
    "                [\"Upload Image\", \"Use Sample Image\", \"Camera Capture\"],\n",
    "                horizontal=True,\n",
    "            )\n",
    "\n",
    "            uploaded_image = None\n",
    "\n",
    "            if image_source == \"Upload Image\":\n",
    "                uploaded_image = st.file_uploader(\n",
    "                    \"Choose an image file\",\n",
    "                    type=[\"png\", \"jpg\", \"jpeg\", \"gif\", \"bmp\"],\n",
    "                    help=\"Upload an image for multimodal analysis\",\n",
    "                )\n",
    "\n",
    "            elif image_source == \"Use Sample Image\":\n",
    "                sample_options = [\"Sample 1\", \"Sample 2\", \"Sample 3\"]\n",
    "                selected_sample = st.selectbox(\"Select Sample:\", sample_options)\n",
    "                st.info(f\"Using {selected_sample} (simulated)\")\n",
    "\n",
    "            elif image_source == \"Camera Capture\":\n",
    "                camera_image = st.camera_input(\"Take a picture\")\n",
    "                if camera_image:\n",
    "                    uploaded_image = camera_image\n",
    "\n",
    "            # Display image if available\n",
    "            if uploaded_image:\n",
    "                try:\n",
    "                    image = Image.open(uploaded_image)\n",
    "                    st.image(image, caption=\"Input Image\", use_column_width=True)\n",
    "\n",
    "                    # Image metadata\n",
    "                    st.write(\n",
    "                        f\"**Image Info:** {image.size[0]}x{image.size[1]} pixels, {image.mode} mode\"\n",
    "                    )\n",
    "\n",
    "                except Exception as e:\n",
    "                    st.error(f\"Error loading image: {str(e)}\")\n",
    "\n",
    "        with col2:\n",
    "            st.subheader(\"üìä Tabular Data Input\")\n",
    "\n",
    "            # Tabular data input options\n",
    "            data_input_method = st.radio(\n",
    "                \"Data Input Method:\",\n",
    "                [\"Manual Entry\", \"CSV Upload\", \"Generate Sample\"],\n",
    "                horizontal=True,\n",
    "            )\n",
    "\n",
    "            tabular_data = None\n",
    "\n",
    "            if data_input_method == \"Manual Entry\":\n",
    "                st.write(\"**Enter feature values:**\")\n",
    "\n",
    "                # Create input fields for features (example)\n",
    "                feature_values = {}\n",
    "                feature_names = [f\"Feature_{i + 1}\" for i in range(5)]\n",
    "\n",
    "                for feature in feature_names:\n",
    "                    feature_values[feature] = st.number_input(\n",
    "                        feature, value=0.0, step=0.1, help=f\"Enter value for {feature}\"\n",
    "                    )\n",
    "\n",
    "                tabular_data = list(feature_values.values())\n",
    "\n",
    "            elif data_input_method == \"CSV Upload\":\n",
    "                csv_file = st.file_uploader(\n",
    "                    \"Upload CSV file\",\n",
    "                    type=[\"csv\"],\n",
    "                    help=\"Upload a CSV file with feature data\",\n",
    "                )\n",
    "\n",
    "                if csv_file:\n",
    "                    try:\n",
    "                        df = pd.read_csv(csv_file)\n",
    "                        st.dataframe(df.head())\n",
    "\n",
    "                        if st.button(\"Use First Row\"):\n",
    "                            tabular_data = df.iloc[0].values.tolist()\n",
    "                            st.success(\"Data loaded successfully!\")\n",
    "\n",
    "                    except Exception as e:\n",
    "                        st.error(f\"Error reading CSV: {str(e)}\")\n",
    "\n",
    "            elif data_input_method == \"Generate Sample\":\n",
    "                if st.button(\"üé≤ Generate Random Sample\"):\n",
    "                    tabular_data = np.random.rand(5).tolist()\n",
    "                    st.success(\"Sample data generated!\")\n",
    "\n",
    "                    # Display generated data\n",
    "                    sample_df = pd.DataFrame(\n",
    "                        {\n",
    "                            \"Feature\": [f\"Feature_{i + 1}\" for i in range(5)],\n",
    "                            \"Value\": tabular_data,\n",
    "                        }\n",
    "                    )\n",
    "                    st.dataframe(sample_df)\n",
    "\n",
    "        # Prediction section\n",
    "        st.markdown(\"---\")\n",
    "        st.subheader(\"ü§ñ AI Prediction\")\n",
    "\n",
    "        col1, col2, col3 = st.columns([1, 1, 1])\n",
    "\n",
    "        with col2:\n",
    "            if st.button(\n",
    "                \"üîÆ Generate Prediction\", type=\"primary\", use_container_width=True\n",
    "            ):\n",
    "                if uploaded_image is not None or tabular_data is not None:\n",
    "                    self.process_multimodal_prediction(uploaded_image, tabular_data)\n",
    "                else:\n",
    "                    st.warning(\n",
    "                        \"Please provide either an image and/or tabular data for prediction.\"\n",
    "                    )\n",
    "\n",
    "        # Display recent predictions\n",
    "        if st.session_state.prediction_results:\n",
    "            st.subheader(\"üìà Recent Predictions\")\n",
    "\n",
    "            # Show latest prediction in detail\n",
    "            latest_prediction = st.session_state.prediction_results[-1]\n",
    "\n",
    "            st.markdown('<div class=\"success-box\">', unsafe_allow_html=True)\n",
    "            st.write(\n",
    "                f\"**Latest Prediction:** {latest_prediction.get('predicted_class', 'N/A')}\"\n",
    "            )\n",
    "            st.write(f\"**Confidence:** {latest_prediction.get('confidence', 0):.3f}\")\n",
    "            st.write(f\"**Timestamp:** {latest_prediction.get('timestamp', 'N/A')}\")\n",
    "            st.markdown(\"</div>\", unsafe_allow_html=True)\n",
    "\n",
    "            # Show prediction history\n",
    "            if len(st.session_state.prediction_results) > 1:\n",
    "                with st.expander(\"üìä Prediction History\"):\n",
    "                    history_df = pd.DataFrame(st.session_state.prediction_results)\n",
    "                    st.dataframe(history_df)\n",
    "\n",
    "    def render_chatbot_interface(self):\n",
    "        \"\"\"Render the RAG-powered chatbot interface\"\"\"\n",
    "        st.header(\"üí¨ RAG-Powered Intelligent Chatbot\")\n",
    "\n",
    "        st.markdown(\n",
    "            \"\"\"\n",
    "        <div class=\"info-box\">\n",
    "            <h4>ü§ñ Chatbot Capabilities</h4>\n",
    "            <ul>\n",
    "                <li><strong>üìö Knowledge Retrieval:</strong> Access to comprehensive document knowledge base</li>\n",
    "                <li><strong>üß† Context Awareness:</strong> Maintains conversation context and history</li>\n",
    "                <li><strong>üîç Source Attribution:</strong> Shows relevant source documents for answers</li>\n",
    "                <li><strong>üí° Intelligent Responses:</strong> Advanced language understanding and generation</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "        \"\"\",\n",
    "            unsafe_allow_html=True,\n",
    "        )\n",
    "\n",
    "        # Conversation interface\n",
    "        st.subheader(\"üí≠ Conversation\")\n",
    "\n",
    "        # Display conversation history\n",
    "        if st.session_state.conversation_history:\n",
    "            with st.container():\n",
    "                for i, (question, answer, timestamp) in enumerate(\n",
    "                    st.session_state.conversation_history\n",
    "                ):\n",
    "                    # User question\n",
    "                    st.markdown(\n",
    "                        f\"\"\"\n",
    "                    <div style=\"background-color: #e3f2fd; padding: 10px; border-radius: 10px; margin: 5px 0;\">\n",
    "                        <strong>üôã You:</strong> {question}\n",
    "                        <div style=\"font-size: 0.8em; color: #666; text-align: right;\">{timestamp}</div>\n",
    "                    </div>\n",
    "                    \"\"\",\n",
    "                        unsafe_allow_html=True,\n",
    "                    )\n",
    "\n",
    "                    # AI response\n",
    "                    st.markdown(\n",
    "                        f\"\"\"\n",
    "                    <div style=\"background-color: #f3e5f5; padding: 10px; border-radius: 10px; margin: 5px 0;\">\n",
    "                        <strong>ü§ñ AI:</strong> {answer}\n",
    "                    </div>\n",
    "                    \"\"\",\n",
    "                        unsafe_allow_html=True,\n",
    "                    )\n",
    "\n",
    "        # Input section\n",
    "        st.markdown(\"---\")\n",
    "\n",
    "        col1, col2 = st.columns([4, 1])\n",
    "\n",
    "        with col1:\n",
    "            user_question = st.text_input(\n",
    "                \"Ask a question:\",\n",
    "                placeholder=\"Enter your question here...\",\n",
    "                help=\"Ask any question about the available knowledge base\",\n",
    "                key=\"user_input\",\n",
    "            )\n",
    "\n",
    "        with col2:\n",
    "            send_button = st.button(\"üì§ Send\", type=\"primary\")\n",
    "\n",
    "        # Quick question suggestions\n",
    "        st.subheader(\"üí° Suggested Questions\")\n",
    "\n",
    "        suggested_questions = [\n",
    "            \"What are the key features of this AI system?\",\n",
    "            \"How does multimodal learning work?\",\n",
    "            \"Explain the RAG approach to question answering\",\n",
    "            \"What are the benefits of combining vision and tabular data?\",\n",
    "        ]\n",
    "\n",
    "        col1, col2 = st.columns(2)\n",
    "\n",
    "        for i, suggestion in enumerate(suggested_questions):\n",
    "            col = col1 if i % 2 == 0 else col2\n",
    "\n",
    "            with col:\n",
    "                if st.button(f\"üí° {suggestion}\", key=f\"suggestion_{i}\"):\n",
    "                    user_question = suggestion\n",
    "                    st.session_state.user_input = suggestion\n",
    "                    send_button = True\n",
    "\n",
    "        # Process question\n",
    "        if send_button and user_question:\n",
    "            self.process_chatbot_question(user_question)\n",
    "            st.rerun()\n",
    "\n",
    "        # Conversation controls\n",
    "        st.markdown(\"---\")\n",
    "        col1, col2, col3 = st.columns(3)\n",
    "\n",
    "        with col1:\n",
    "            if st.button(\"üîÑ New Conversation\"):\n",
    "                st.session_state.conversation_history = []\n",
    "                st.session_state.current_conversation_id = f\"session_{int(time.time())}\"\n",
    "                st.rerun()\n",
    "\n",
    "        with col2:\n",
    "            if st.button(\"üíæ Export Chat\"):\n",
    "                self.export_conversation_history()\n",
    "\n",
    "        with col3:\n",
    "            if st.button(\"üìä Conversation Stats\"):\n",
    "                self.show_conversation_stats()\n",
    "\n",
    "    def render_analytics_dashboard(self):\n",
    "        \"\"\"Render comprehensive analytics dashboard\"\"\"\n",
    "        st.header(\"üìä Advanced Analytics Dashboard\")\n",
    "\n",
    "        # System performance metrics\n",
    "        st.subheader(\"üöÄ System Performance\")\n",
    "\n",
    "        col1, col2, col3, col4 = st.columns(4)\n",
    "\n",
    "        stats = st.session_state.system_stats\n",
    "\n",
    "        with col1:\n",
    "            st.metric(\n",
    "                \"Total Predictions\",\n",
    "                stats[\"total_predictions\"],\n",
    "                delta=1 if stats[\"total_predictions\"] > 0 else 0,\n",
    "            )\n",
    "\n",
    "        with col2:\n",
    "            st.metric(\n",
    "                \"Conversations\",\n",
    "                stats[\"total_conversations\"],\n",
    "                delta=1 if stats[\"total_conversations\"] > 0 else 0,\n",
    "            )\n",
    "\n",
    "        with col3:\n",
    "            avg_conf = stats.get(\"avg_confidence\", 0)\n",
    "            st.metric(\n",
    "                \"Avg Confidence\",\n",
    "                f\"{avg_conf:.3f}\",\n",
    "                delta=f\"{avg_conf - 0.5:.3f}\" if avg_conf > 0 else \"0.000\",\n",
    "            )\n",
    "\n",
    "        with col4:\n",
    "            uptime = datetime.now() - stats[\"session_start\"]\n",
    "            st.metric(\"Session Time\", f\"{uptime.seconds // 60}m\", delta=\"Active\")\n",
    "\n",
    "        # Visualization section\n",
    "        if st.session_state.prediction_results:\n",
    "            st.subheader(\"üìà Prediction Analytics\")\n",
    "\n",
    "            # Create sample visualization\n",
    "            prediction_df = pd.DataFrame(st.session_state.prediction_results)\n",
    "\n",
    "            # Confidence distribution\n",
    "            fig_confidence = px.histogram(\n",
    "                prediction_df,\n",
    "                x=\"confidence\",\n",
    "                title=\"Prediction Confidence Distribution\",\n",
    "                nbins=20,\n",
    "            )\n",
    "            st.plotly_chart(fig_confidence, use_container_width=True)\n",
    "\n",
    "            # Prediction timeline\n",
    "            if \"timestamp\" in prediction_df.columns:\n",
    "                fig_timeline = px.line(\n",
    "                    prediction_df.reset_index(),\n",
    "                    x=\"timestamp\",\n",
    "                    y=\"confidence\",\n",
    "                    title=\"Prediction Confidence Over Time\",\n",
    "                )\n",
    "                st.plotly_chart(fig_timeline, use_container_width=True)\n",
    "\n",
    "        # Conversation analytics\n",
    "        if st.session_state.conversation_history:\n",
    "            st.subheader(\"üí¨ Conversation Analytics\")\n",
    "\n",
    "            # Conversation length analysis\n",
    "            question_lengths = [\n",
    "                len(q.split()) for q, a, t in st.session_state.conversation_history\n",
    "            ]\n",
    "            answer_lengths = [\n",
    "                len(a.split()) for q, a, t in st.session_state.conversation_history\n",
    "            ]\n",
    "\n",
    "            fig_lengths = go.Figure()\n",
    "            fig_lengths.add_trace(\n",
    "                go.Scatter(\n",
    "                    y=question_lengths,\n",
    "                    mode=\"lines+markers\",\n",
    "                    name=\"Question Length\",\n",
    "                    line=dict(color=\"blue\"),\n",
    "                )\n",
    "            )\n",
    "            fig_lengths.add_trace(\n",
    "                go.Scatter(\n",
    "                    y=answer_lengths,\n",
    "                    mode=\"lines+markers\",\n",
    "                    name=\"Answer Length\",\n",
    "                    line=dict(color=\"red\"),\n",
    "                )\n",
    "            )\n",
    "            fig_lengths.update_layout(title=\"Conversation Flow Analysis\")\n",
    "\n",
    "            st.plotly_chart(fig_lengths, use_container_width=True)\n",
    "\n",
    "    def render_documentation(self):\n",
    "        \"\"\"Render system documentation and help\"\"\"\n",
    "        st.header(\"üìñ System Documentation\")\n",
    "\n",
    "        # Documentation tabs\n",
    "        doc_tab1, doc_tab2, doc_tab3, doc_tab4 = st.tabs(\n",
    "            [\n",
    "                \"üöÄ Getting Started\",\n",
    "                \"üéØ Multimodal AI\",\n",
    "                \"üí¨ RAG Chatbot\",\n",
    "                \"üîß API Reference\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        with doc_tab1:\n",
    "            st.markdown(\"\"\"\n",
    "            ## üöÄ Getting Started with Advanced AI System Suite\n",
    "            \n",
    "            ### Overview\n",
    "            This application combines two powerful AI technologies:\n",
    "            1. **Multimodal AI System** - Combines computer vision and tabular data analysis\n",
    "            2. **RAG-Powered Chatbot** - Intelligent conversational AI with knowledge retrieval\n",
    "            \n",
    "            ### Quick Start Guide\n",
    "            1. **For Multimodal Predictions:**\n",
    "               - Navigate to the \"üéØ Multimodal AI\" tab\n",
    "               - Upload an image or use camera capture\n",
    "               - Enter tabular data or upload CSV\n",
    "               - Click \"Generate Prediction\"\n",
    "            \n",
    "            2. **For Chatbot Conversations:**\n",
    "               - Go to \"üí¨ RAG Chatbot\" tab\n",
    "               - Type your question or select a suggested question\n",
    "               - Review the AI response and source documents\n",
    "            \n",
    "            3. **Analytics & Monitoring:**\n",
    "               - Check \"üìä Analytics Dashboard\" for performance metrics\n",
    "               - Monitor system statistics in the sidebar\n",
    "            \"\"\")\n",
    "\n",
    "        with doc_tab2:\n",
    "            st.markdown(\"\"\"\n",
    "            ## üéØ Multimodal AI System Documentation\n",
    "            \n",
    "            ### Architecture\n",
    "            The system uses advanced neural network architectures to process and combine:\n",
    "            - **Image Data**: Convolutional Neural Networks (CNNs) for feature extraction\n",
    "            - **Tabular Data**: Dense neural networks for structured data processing\n",
    "            - **Fusion Layer**: Intelligent combination of multimodal features\n",
    "            \n",
    "            ### Supported Formats\n",
    "            - **Images**: PNG, JPG, JPEG, GIF, BMP\n",
    "            - **Tabular Data**: CSV files, manual entry, generated samples\n",
    "            \n",
    "            ### Performance Metrics\n",
    "            - **Accuracy**: Model prediction accuracy on test data\n",
    "            - **Confidence**: Prediction confidence scores (0.0 - 1.0)\n",
    "            - **Processing Time**: Time taken for inference\n",
    "            \"\"\")\n",
    "\n",
    "        with doc_tab3:\n",
    "            st.markdown(\"\"\"\n",
    "            ## üí¨ RAG Chatbot Documentation\n",
    "            \n",
    "            ### How RAG Works\n",
    "            Retrieval-Augmented Generation (RAG) combines:\n",
    "            1. **Document Retrieval**: Finding relevant documents from knowledge base\n",
    "            2. **Context Integration**: Combining retrieved information with the question\n",
    "            3. **Response Generation**: Using LLM to generate contextual answers\n",
    "            \n",
    "            ### Features\n",
    "            - **Context Awareness**: Maintains conversation history\n",
    "            - **Source Attribution**: Shows which documents inform each answer\n",
    "            - **Multiple Knowledge Bases**: Support for various document types\n",
    "            - **Real-time Learning**: Dynamic knowledge base updates\n",
    "            \n",
    "            ### Best Practices\n",
    "            - Ask specific, clear questions\n",
    "            - Use follow-up questions for clarification\n",
    "            - Review source documents for additional context\n",
    "            \"\"\")\n",
    "\n",
    "        with doc_tab4:\n",
    "            st.markdown(\"\"\"\n",
    "            ## üîß API Reference\n",
    "            \n",
    "            ### Core Functions\n",
    "            \n",
    "            #### Multimodal Prediction\n",
    "            ```python\n",
    "            prediction = model.predict_multimodal(\n",
    "                image_data=image_array,\n",
    "                tabular_data=feature_vector,\n",
    "                return_confidence=True\n",
    "            )\n",
    "            ```\n",
    "            \n",
    "            #### Chatbot Query\n",
    "            ```python\n",
    "            response = chatbot.ask_question(\n",
    "                question=\"Your question here\",\n",
    "                conversation_id=\"session_id\",\n",
    "                include_sources=True\n",
    "            )\n",
    "            ```\n",
    "            \n",
    "            ### Configuration Options\n",
    "            - **Confidence Threshold**: Minimum confidence for predictions\n",
    "            - **Response Detail**: Level of detail in chatbot responses\n",
    "            - **Source Display**: Show/hide source documents\n",
    "            - **Session Management**: Conversation persistence settings\n",
    "            \"\"\")\n",
    "\n",
    "    def process_multimodal_prediction(self, image, tabular_data):\n",
    "        \"\"\"Process multimodal prediction with mock implementation\"\"\"\n",
    "        with st.spinner(\"üîÆ Generating AI prediction...\"):\n",
    "            time.sleep(2)  # Simulate processing time\n",
    "\n",
    "            # Mock prediction results\n",
    "            mock_classes = [\"Class_A\", \"Class_B\", \"Class_C\", \"Class_D\"]\n",
    "            predicted_class = random.choice(mock_classes)\n",
    "            confidence = random.uniform(0.6, 0.95)\n",
    "\n",
    "            # Create prediction result\n",
    "            prediction_result = {\n",
    "                \"predicted_class\": predicted_class,\n",
    "                \"confidence\": confidence,\n",
    "                \"probabilities\": {\n",
    "                    cls: random.uniform(0.1, 0.9) for cls in mock_classes\n",
    "                },\n",
    "                \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"processing_time\": 2.0,\n",
    "            }\n",
    "\n",
    "            # Update session state\n",
    "            st.session_state.prediction_results.append(prediction_result)\n",
    "            st.session_state.system_stats[\"total_predictions\"] += 1\n",
    "\n",
    "            # Update average confidence\n",
    "            all_confidences = [\n",
    "                p[\"confidence\"] for p in st.session_state.prediction_results\n",
    "            ]\n",
    "            st.session_state.system_stats[\"avg_confidence\"] = np.mean(all_confidences)\n",
    "\n",
    "            st.success(\n",
    "                f\"‚úÖ Prediction completed! Class: {predicted_class}, Confidence: {confidence:.3f}\"\n",
    "            )\n",
    "\n",
    "    def process_chatbot_question(self, question):\n",
    "        \"\"\"Process chatbot question with mock implementation\"\"\"\n",
    "        with st.spinner(\"ü§ñ Generating intelligent response...\"):\n",
    "            time.sleep(1.5)  # Simulate processing time\n",
    "\n",
    "            # Mock response generation\n",
    "            mock_responses = [\n",
    "                f\"Based on the available knowledge base, regarding '{question[:30]}...', I can provide the following information: This is a comprehensive response that addresses your question with relevant details and context.\",\n",
    "                f\"Thank you for your question about '{question[:30]}...'. From the documentation and available resources, here's what I found: This response includes detailed explanations and relevant background information.\",\n",
    "                f\"Excellent question! Regarding '{question[:30]}...', the system documentation indicates: Here's a thorough response with technical details and practical insights.\",\n",
    "            ]\n",
    "\n",
    "            response = random.choice(mock_responses)\n",
    "            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "            # Add to conversation history\n",
    "            st.session_state.conversation_history.append(\n",
    "                (question, response, timestamp)\n",
    "            )\n",
    "            st.session_state.system_stats[\"total_conversations\"] += 1\n",
    "\n",
    "            st.success(\"‚úÖ Response generated successfully!\")\n",
    "\n",
    "    def clear_session_data(self):\n",
    "        \"\"\"Clear all session data\"\"\"\n",
    "        st.session_state.conversation_history = []\n",
    "        st.session_state.prediction_results = []\n",
    "        st.session_state.system_stats = {\n",
    "            \"total_predictions\": 0,\n",
    "            \"total_conversations\": 0,\n",
    "            \"avg_confidence\": 0,\n",
    "            \"session_start\": datetime.now(),\n",
    "        }\n",
    "        st.success(\"üóëÔ∏è Session data cleared successfully!\")\n",
    "\n",
    "    def export_session_data(self):\n",
    "        \"\"\"Export session data to JSON\"\"\"\n",
    "        export_data = {\n",
    "            \"session_stats\": st.session_state.system_stats,\n",
    "            \"predictions\": st.session_state.prediction_results,\n",
    "            \"conversations\": st.session_state.conversation_history,\n",
    "            \"export_timestamp\": datetime.now().isoformat(),\n",
    "        }\n",
    "\n",
    "        # Convert to JSON string\n",
    "        json_str = json.dumps(export_data, indent=2, default=str)\n",
    "\n",
    "        # Create download button\n",
    "        st.download_button(\n",
    "            label=\"üíæ Download Session Data\",\n",
    "            data=json_str,\n",
    "            file_name=f\"ai_session_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\",\n",
    "            mime=\"application/json\",\n",
    "        )\n",
    "\n",
    "    def process_uploaded_documents(self, uploaded_files):\n",
    "        \"\"\"Process uploaded documents for knowledge base\"\"\"\n",
    "        with st.spinner(f\"üìö Processing {len(uploaded_files)} documents...\"):\n",
    "            time.sleep(2)  # Simulate processing\n",
    "\n",
    "            for file in uploaded_files:\n",
    "                st.session_state.knowledge_bases.append(\n",
    "                    {\n",
    "                        \"filename\": file.name,\n",
    "                        \"size\": file.size,\n",
    "                        \"uploaded_at\": datetime.now().isoformat(),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            st.success(f\"‚úÖ Successfully processed {len(uploaded_files)} documents!\")\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Run the complete Streamlit application\"\"\"\n",
    "        self.render_header()\n",
    "        self.render_sidebar()\n",
    "        self.render_main_interface()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# APPLICATION LAUNCHER\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main application entry point\"\"\"\n",
    "    try:\n",
    "        # Initialize and run the advanced Streamlit app\n",
    "        app = AdvancedStreamlitApp()\n",
    "        app.run()\n",
    "\n",
    "    except Exception as e:\n",
    "        st.error(f\"‚ùå Application Error: {str(e)}\")\n",
    "        st.info(\"Please check the system logs and try refreshing the page.\")\n",
    "\n",
    "\n",
    "# Launch the application\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# =============================================================================\n",
    "# DEPLOYMENT INSTRUCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "---\n",
    "### üöÄ Deployment Instructions\n",
    "\n",
    "To run this Streamlit application:\n",
    "\n",
    "```bash\n",
    "# Install required packages\n",
    "pip install streamlit plotly pandas pillow numpy\n",
    "\n",
    "# Run the application\n",
    "streamlit run advanced_ai_app.py\n",
    "\n",
    "# The application will be available at:\n",
    "# Local URL: http://localhost:8501\n",
    "# Network URL: http://[your-ip]:8501\n",
    "```\n",
    "\n",
    "### üì± Mobile Compatibility\n",
    "This application is fully responsive and works on:\n",
    "- üíª Desktop browsers\n",
    "- üì± Mobile devices\n",
    "- üìü Tablet interfaces\n",
    "\n",
    "### üîß Configuration Options\n",
    "- Modify the `page_config` for custom branding\n",
    "- Adjust the CSS styling for different themes\n",
    "- Configure API endpoints for production deployment\n",
    "- Set up authentication and user management as needed\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nüåê Advanced Streamlit Application Ready!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üí° To launch the application:\")\n",
    "print(\"   streamlit run [this_notebook_as_python_file]\")\n",
    "print(\"üì± The app will be available at: http://localhost:8501\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
