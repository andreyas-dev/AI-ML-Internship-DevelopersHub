# ❤️ Task 3 – Heart Disease Prediction

This project is part of my **AI/ML Internship Task 3**, focused on predicting whether a person is at risk of heart disease based on medical and lifestyle data 🫀.  
The task involves **data cleaning**, **exploratory data analysis (EDA)**, **model training**, and **evaluation**.

---

## 🎯 Objectives
- 📥 **Load & Inspect** the UCI Heart Disease dataset  
- 📊 **Perform EDA** to understand feature distributions and relationships  
- 🤖 **Train Classification Models** — Decision Tree, Logistic Regression  
- 📉 **Evaluate Models** using Accuracy, Confusion Matrix, ROC Curve, and Feature Importance  
- 📈 **Visualize Results** for interpretability and insight  

---

## 📂 Folder Contents
- 📒 **heart_disease_prediction.ipynb** → Jupyter Notebook with full implementation  
- 🖼 **results/**  → Saved plots including confusion matrices, ROC curves, and feature importance charts  

---

## 🚀 How to Run
1. 📂 **Open Notebook:** Launch `heart_disease_prediction.ipynb` in **Jupyter Notebook**  
2. ▶️ **Run Cells:** Execute sequentially to load data, preprocess, train models, and evaluate predictions  
3. 👀 **Analyze Results:** Review:
   - 📊 **Model Metrics** — Accuracy, Confusion Matrix, ROC Curve  
   - 📈 **Feature Importance** — Attributes with most predictive power  

---

## 📊 Dataset Information
- **Source:** [UCI Heart Disease Dataset](https://archive.ics.uci.edu/ml/datasets/heart+disease)  
- **Description:** Contains medical and lifestyle features such as:
  - Age, Gender, Chest Pain Type
  - Resting Blood Pressure, Cholesterol
  - Maximum Heart Rate Achieved, Fasting Blood Sugar
  - And others  
- **Target Variable:** Presence (1) or absence (0) of heart disease  

---

## 🤖 Models Implemented
1. **Decision Tree Classifier**  
   - Achieved **62% accuracy**  
   - Evaluation: Confusion Matrix, ROC Curve, Feature Importance  
2. **Logistic Regression**  
   - Achieved **50% accuracy**  
   - Evaluation: Confusion Matrix, ROC Curve, Coefficient-based Feature Importance  

---

## 📌 Key Insights & Findings
- Decision Tree performed better than Logistic Regression.  
- Practical experience gained in:
  - Data preprocessing and handling missing/outlier values  
  - Performing EDA on medical datasets  
  - Building and interpreting classification models  
- **Future Improvements:**
  - Hyperparameter tuning for better accuracy  
  - Try ensemble models like Random Forest or Gradient Boosting  
  - Feature engineering to uncover hidden patterns  

---

## 🛠 Tech Stack
- 🐍 **Language:** Python  
- 📚 **Libraries:** `pandas`, `numpy`, `matplotlib`, `seaborn`, `scikit-learn`, `joblib`  

---

## 📫 Contact
- **LinkedIn:** [Your Name](www.linkedin.com/in/eng-andreyas)  
- **Email:** eng.andreyas@gmail.com  

---

## ✅ Status
**Task Completed Successfully** – all models trained, evaluated, and results visualized.

